{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fraud_detection_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBhw1Duodx+MyBhfacmVi2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pfolaa/fraud_detection/blob/main/fraud_detection_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBkuHMcekLs0",
        "outputId": "22bcf1e6-7bb7-49e9-b412-283dd6f4f9f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlJ4DsLDm3OP"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import glob2\n",
        "import tqdm\n",
        "import json\n",
        "import pandas as pd\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxvxpGmXjwcU",
        "outputId": "2d4a6aa4-71d1-413d-9d1b-0311fc2bf586"
      },
      "source": [
        "cd /content/drive/MyDrive/datasets/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v1c4xv3jFmT"
      },
      "source": [
        "def read_json_insert_csv(root_path, json_file, file_csv):\n",
        "  data = json.load(json_file)\n",
        "  df = pd.DataFrame.from_records(data)\n",
        "  # convert file to csv\n",
        "  df.to_csv(f'{root_path}/{file_csv}', \n",
        "            sep='|', \n",
        "            index= None)\n",
        "\n",
        "  # return 1 fichier csv fer json file\n",
        "  return df "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TZcB6c4jX06"
      },
      "source": [
        "def process_json( path_file_json=\"./nirra-log-bot\", dest_path=\"./liberta_leasing\"):\n",
        "  # créer toute l'aborescence du fichier, crée le chemin\n",
        "  os.makedirs(dest_path, exist_ok=True) \n",
        "  # read all json files\n",
        "\n",
        "  json_files = glob2.glob(os.path.join(path_file_json,'*.json'))\n",
        "  for file_name in tqdm.tqdm(json_files):\n",
        "    with open(file_name) as json_file:\n",
        "      path_file_csv = file_name.replace(\".json\", \".csv\").split(\"/\")[-1]\n",
        "      read_json_insert_csv(dest_path, json_file, path_file_csv)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5g5SpxFmowA",
        "outputId": "f55b824d-53f3-4b83-cb90-ca5535c939a5"
      },
      "source": [
        "process_json('./nirra-log-bot', './liberta_leasing')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 171/171 [02:17<00:00,  1.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noiqJADKqiG2",
        "outputId": "d895ff4a-f9a5-416a-94aa-57e0776b613c"
      },
      "source": [
        "cd /content/drive/MyDrive/datasets/liberta_leasing/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets/liberta_leasing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFG_FlZCqhVf",
        "outputId": "522a4515-03a4-4e70-96ca-5aa9a21f833d"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# use glob to get all the csv files \n",
        "# in the folder\n",
        "path = os.getcwd()\n",
        "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "all_df_list = [] # list of all dataframe\n",
        "for f in tqdm(csv_files):    \n",
        "    # read the csv file\n",
        "    #col_names = [\"type\", \"subtype\", \"text\", \"ts\", \"bot_id\"]\n",
        "    df=pd.read_csv(f, sep=\"|\")\n",
        "    all_df_list.append(df) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 171/171 [00:00<00:00, 195.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzFoFdsXsBqG",
        "outputId": "6d6c7cd2-f9e1-4baa-e950-96eba050f4ee"
      },
      "source": [
        "print(len(all_df_list))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "8PM0Fv1PL36b",
        "outputId": "96d228e4-0b06-401c-e927-4249e957d0c6"
      },
      "source": [
        "all_df_list[0][all_df_list[0]['type']== 'type']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>subtype</th>\n",
              "      <th>text</th>\n",
              "      <th>ts</th>\n",
              "      <th>bot_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [type, subtype, text, ts, bot_id]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm7b9wtC3MWT"
      },
      "source": [
        "### Concatener tous les dataframe en un seul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeyAENxG1h9m"
      },
      "source": [
        "df_raw = pd.concat(all_df_list, ignore_index=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaZ3gAcgEvrt"
      },
      "source": [
        "df_raw.to_csv('/content/drive/MyDrive/datasets/nirra_log_bot.csv', index=None, sep='|')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyLEBiBuNxJN",
        "outputId": "f0ef70df-f199-4e37-e722-75cabbc030aa"
      },
      "source": [
        "df_temp = pd.read_csv('/content/drive/MyDrive/datasets/nirra_log_bot.csv', sep='|')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYCxywmRODjf"
      },
      "source": [
        "df_temp.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlkOAge1sVOr"
      },
      "source": [
        "def parse_wallet_sms_payload_success(text_type_request):\n",
        "  ''' la fonction permet de parser les types de requete \"Okra WebHook\", \"Wallet success\", \n",
        "      \"SMS Success\" et SMS Payload en object json.\n",
        "      Elle prend en paramètre le text contenu dans le type de requete,\n",
        "      elle retourne un objet de type JSON.'''\n",
        "\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_type_request)\n",
        "  res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "  s = json.loads(res)\n",
        "  out_dict = {} # dictionnary vide\n",
        "  for key, value in s.items():\n",
        "    out_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "\n",
        "\n",
        "  out_dump = json.dumps(out_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "  out_wallet_success = json.loads(out_dump) # convertir le string json en object json.\n",
        "  return out_wallet_success\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXFZHNE_Eft4"
      },
      "source": [
        "def parse_providus_transfer_error_function(text_type_request):\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_type_request)\n",
        "  if len(resul_patt) != 0:\n",
        "    res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "    s = json.loads(res)\n",
        "    out_dict = {} # dictionnary vide\n",
        "    for key, value in s.items():\n",
        "      out_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "    out_dump = json.dumps(out_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "    out_wallet_success = json.loads(out_dump) # convertir le string json en object json.\n",
        "    return out_wallet_success\n",
        "  else:\n",
        "    resultat = 'Transfer to virtual account is not allowed!'\n",
        "    return resultat\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv7AQb4Ysb5D"
      },
      "source": [
        "import re\n",
        "\n",
        "# la fonction doit prendre en paramètre quelque chose\n",
        "def parse_and_concatenate_Leadway_Success_Rows(df_raw):\n",
        "  '''Cette fonction permet de parser et de concatener le texte qui a LEADWAY SUCCESS\n",
        "     comme type de requete\n",
        "     elle prend comme paramètre un dataframe et retourne les valeurs suivantes:\n",
        "     - un texte concatené\n",
        "     - l'index de la 1ère ligne qu'on va utiliser ensuite pour l'effacer\n",
        "     - l'index de la dernière ligne qu'on va utiliser ensuite pour l'effacer '''\n",
        "\n",
        "  first_index = 0\n",
        "  last_index = 0\n",
        "  text_leadway_concat = ''\n",
        "  for index, row in df_raw.iterrows():  # boucler sur les colonnes de type text\n",
        "      text_row = row['text']  \n",
        "      if re.search('LEADWAY SUCCESS', text_row):\n",
        "        text_leadway_concat = text_row\n",
        "        first_index = index\n",
        "        first_index +=1\n",
        "        new_df = df_raw[first_index:]\n",
        "        for first_index, new_row in new_df.iterrows():\n",
        "          xxx = new_row['text']      \n",
        "          if not xxx.startswith('['):          \n",
        "            first_index += 1\n",
        "            text_leadway_concat = text_row + xxx       \n",
        "          elif xxx.startswith('['):\n",
        "            last_index = first_index-1\n",
        "            break\n",
        "\n",
        "\n",
        "  return text_leadway_concat, first_index, last_index\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1_on8resgdJ"
      },
      "source": [
        "\n",
        "# use this function when type request is LEADWAY SUCCESS\n",
        "import regex\n",
        "import json\n",
        "\n",
        "\n",
        "def parse_Leadway_Success_Row(text_leadway):\n",
        "  ''' fonction permettant de parser le text concatené pour le type de requet LEADWAY SUCCESS\n",
        "      elle retourner un dictionnaire.'''\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_leadway)\n",
        "  resul_patt[0] = resul_patt[0].replace(\"\\\\\", \"\")\n",
        "  x = resul_patt[0].replace(\"make,\", \"\")\n",
        "  y = x.replace('\"\"makeName\"', '\"makeName\"')\n",
        "  z = json.loads(y)\n",
        "  vehicleMake = z.get('vehicleMake')\n",
        "  leadway_dict = {}\n",
        "  for element in vehicleMake:\n",
        "    leadway_dict[element['id']] = element['makeName']\n",
        "\n",
        "  return leadway_dict"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u470nALIsoTx"
      },
      "source": [
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_Error_Row(error_row):\n",
        "  error_row = error_row.replace('\"', \"'\")\n",
        "  pattern = regex.compile(r\"{?[a-z :A-Z 0-9\\\\,=_`']+selfie\")\n",
        "  resul_patt = pattern.findall(error_row)\n",
        "  res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "  res = res.replace(\"'name'\", \"name\").replace(\"`\", \"\").replace(\"'18'\", \"18\").replace(\"'monthly'\", \"monthly\")\n",
        "  res = res+'\"}'\n",
        "  res = res.replace(\"'\", '\"')\n",
        "  s = json.loads(res)\n",
        "  out_error_dict = {} # dictionnary vide\n",
        "  for key, value in s.items():\n",
        "    out_error_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "\n",
        "  out_error_dump = json.dumps(out_error_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "  out_error_text = json.loads(out_error_dump) # convertir le string json en object json.\n",
        "  return out_error_text\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKcYlDZoRfqD"
      },
      "source": [
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_Error_Row_selfie_Function(error_row):\n",
        "  error_row = error_row.replace('\"', \"'\")\n",
        "  pattern = regex.compile(r\"({?[a-z :A-Z 0-9\\\\,=_`']+)selfie\")\n",
        "  resul_patt = pattern.findall(error_row)\n",
        "  # checker si la liste contient au moins un element\n",
        "  if len(resul_patt) !=0 :\n",
        "    res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "    res = res+'\"}'\n",
        "    res = res.replace(\"'monthly'\", \"monthly\").replace(\"'\", '\"').replace('\"\"', '\"').replace('\"monthly \", \"', '\"monthly\"')\n",
        "    s = json.loads(res)\n",
        "    out_error_dict = {} # dictionnary vide\n",
        "    for key, value in s.items():\n",
        "      out_error_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "    out_error_dump = json.dumps(out_error_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "    out_error_text = json.loads(out_error_dump)\n",
        "    out_error_text\n",
        "    return out_error_text\n",
        "  #si la liste est vide, on la retourne\n",
        "  else:\n",
        "    return resul_patt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "eMur80eWsFRO",
        "outputId": "ec48752f-bc11-401d-d5c9-4c4fd4fb5f4b"
      },
      "source": [
        "df_raw['text'][26265].replace('\"', \"'\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[info] - ['[VTPASS SUCCESS]:','{\\\\'code\\\\':\\\\'000\\\\',\\\\'content\\\\':{\\\\'transactions\\\\':{\\\\'status\\\\':\\\\'delivered\\\\',\\\\'product_name\\\\':\\\\'MTN Airtime VTU\\\\',\\\\'unique_element\\\\':\\\\'08137772005\\\\',\\\\'unit_price\\\\':200,\\\\'quantity\\\\':1,\\\\'service_verification\\\\':null,\\\\'channel\\\\':\\\\'api\\\\',\\\\'commission\\\\':6,\\\\'total_amount\\\\':194,\\\\'discount\\\\':null,\\\\'type\\\\':\\\\'Airtime Recharge\\\\',\\\\'email\\\\':\\\\'<mailto:ayo@libertaleasing.com|ayo@libertaleasing.com>\\\\',\\\\'phone\\\\':\\\\'08033984930\\\\',\\\\'name\\\\':null,\\\\'convinience_fee\\\\':0,\\\\'amount\\\\':200,\\\\'platform\\\\':\\\\'api\\\\',\\\\'method\\\\':\\\\'api\\\\',\\\\'transactionId\\\\':\\\\'16283673330708221717167202\\\\'}},\\\\'response_description\\\\':\\\\'TRANSACTION SUCCESSFUL\\\\',\\\\'requestId\\\\':\\\\'08177608934-1628367332687\\\\',\\\\'amount\\\\':\\\\'200.00\\\\',\\\\'transaction_date\\\\':{\\\\'date\\\\':\\\\'2021-08-07 21:15:33.000000\\\\',\\\\'timezone_type\\\\':3,\\\\'timezone\\\\':\\\\'Africa/Lagos\\\\'},\\\\'purchased_code\\\\':\\\\'\\\\'}']\""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAQVy3O5xn9u",
        "outputId": "2762c89e-4371-476a-c1dc-613868cf89dc"
      },
      "source": [
        "parse_Error_Row_selfie_Function(df_raw['text'][26265])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBN4__k_x7Gf"
      },
      "source": [
        "def parse_Error_Row_selfie_INSERT_INTO_Function(error_row):\n",
        "  error_row = df_raw['text'][28813]\n",
        "  error_row = error_row.replace('\"', \"'\")\n",
        "  pattern = regex.compile(r\"({?[a-z :A-Z 0-9\\\\,=_`']+)selfie\")\n",
        "  resul_patt = pattern.findall(error_row)\n",
        "  if len(resul_patt) !=0 :\n",
        "      res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "      res = res+'\"}'\n",
        "      res = res.replace(\"'monthly'\", \"monthly\").replace(\"'\", '\"').replace('\"\"', '\"').replace(\"`\", '\"').replace('monthly, \"', '\"monthly\"').replace('\"name\"', 'name')\n",
        "      res = res.replace('\"product\"', 'product').replace('\"loan_amount\"', 'loan_amount').replace('\"tenor\"', 'tenor').replace('\"loan_purpose\"', 'loan_purpose')\n",
        "      res = res.replace('\"14\"', '14').replace('\"tenor_type\"', 'tenor_type').replace('\"monthly\"', 'monthly')\n",
        "      s = json.loads(res)\n",
        "      out_error_dict = {} # dictionnary vide\n",
        "      for key, value in s.items():\n",
        "        out_error_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "      out_error_dump = json.dumps(out_error_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "      out_error_text = json.loads(out_error_dump)\n",
        "      out_error_text\n",
        "      return out_error_text\n",
        "    #si la liste est vide, on la retourne\n",
        "  else:\n",
        "      return resul_patt"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03W0AyZz04cn",
        "outputId": "0892d44b-a8d7-441c-fe48-00e13a62f278"
      },
      "source": [
        "parse_Error_Row_selfie_INSERT_INTO_Function(df_raw['text'][28813])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "550yp0F11MLD",
        "outputId": "d8fd07c2-35a9-469a-c4a1-67322f4a9c18"
      },
      "source": [
        "parse_Error_Row_selfie_INSERT_INTO_Function(df_raw['text'][86636])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EggYXX4ipeBs",
        "outputId": "474af381-3e78-4aef-c594-bd07f391e249"
      },
      "source": [
        "df_raw['text'][28813].replace('\"', \"'\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[info] - ['[API REQUEST]: 07063492113, /client/payment-method/get/4780, 2021-08-13T17:38:59.933Z']\""
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kES3ti8fppDc"
      },
      "source": [
        "err = parse_Error_Row_selfie_Function (df_raw['text'][28813])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZZ0t3_iPhlj"
      },
      "source": [
        "def parse_Error_Row_Function (error_row):\n",
        "  res = []\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(error_row)\n",
        "  for one_res in resul_patt:\n",
        "    res.append(one_res.replace(\"\\\\\", \" \").replace(\"`\", \"\").replace(\"\\'\", \"\"))\n",
        "  list_json = [json.loads(stuff) for stuff in res]\n",
        "  return list_json"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4JECgNVsrrw"
      },
      "source": [
        "import datetime\n",
        "\n",
        "# function to convert date to Timestamp\n",
        "def convertToTimestamp(str):\n",
        "  element = datetime.datetime.strptime(str,\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "  return datetime.datetime.timestamp(element)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8hteMxKsueg"
      },
      "source": [
        "type_request_dictionnary = {}\n",
        "regex_list_api_request = []\n",
        "regex_list_api_request.append('[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
        "regex_list_api_request.append('/[/a-z 0-9?=&;/_A-Z+]+')\n",
        "regex_list_api_request.append('(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d).(\\d{3})*[a-zA-Z]')\n",
        "regex_list_api_request.append('[0-9]+')\n",
        "\n",
        "type_request_dictionnary['API REQUEST'] = regex_list_api_request\n",
        "\n",
        "regex_list_client_mobile = []\n",
        "regex_list_client_mobile.append('[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
        "regex_list_client_mobile.append('(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d).(\\d{3})*[a-zA-Z]')\n",
        "regex_list_client_mobile.append('[0-9]+')\n",
        "\n",
        "type_request_dictionnary['CLIENT MOBILE LOGIN'] = regex_list_client_mobile\n",
        "\n",
        "type_request_dictionnary['SMS PAYLOAD'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['SMS SUCCESS'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['WALLET SUCCESS'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['LEADWAY SUCCESS'] = '\\{(?:[^{}]|(?R))*}'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-m87ITsx60"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "\n",
        "def parse_row_error(df_):\n",
        "  log_level_col = []\n",
        "  type_request_col = []\n",
        "  error_code_col = []\n",
        "  error_number_col = []\n",
        "  error_sql_message_col = []\n",
        "  error_sql_state_col = []\n",
        "  error_index_col = []\n",
        "  error_sql_col = []\n",
        "  loan_amount_col = []\n",
        "  loan_purpose_col = []\n",
        "  product_col = []\n",
        "  tenor_col = []\n",
        "  tenor_type_col = []\n",
        "  error_created_by_col = []\n",
        "  error_creator_type_col = []\n",
        "  error_date_created_col = []\n",
        "  error_name_col = []\n",
        "  error_rate_col = []\n",
        "  error_request_col = []\n",
        "  error_status_col = []\n",
        "  error_userID_col = []\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, log_level_col, error_code_col, error_number_col, error_sql_message_col, error_sql_state_col, \n",
        "                    error_index_col, error_sql_col, loan_amount_col, loan_purpose_col, product_col, tenor_col, tenor_type_col,\n",
        "                    error_created_by_col, error_creator_type_col, error_date_created_col, error_name_col, error_rate_col,\n",
        "                    error_request_col, error_status_col, error_userID_col]\n",
        "\n",
        "  for index, row in df_.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "    \n",
        "    if re.search('error', str_text):\n",
        "      log_level = re.search('error', str_text)\n",
        "      type_of_request = re.search('LOAN ERROR', str_text)\n",
        "\n",
        "      if 'INSERT INTO' not in str_text:  \n",
        "          try:\n",
        "            log_level_col.append(log_level.group(0))\n",
        "          except AttributeError:\n",
        "            log_level_col.append(None)\n",
        "          try:\n",
        "            type_request_col.append(type_of_request.group(0))\n",
        "          except AttributeError:\n",
        "            type_request_col.append(None)         \n",
        "          try:\n",
        "            loan_error = parse_Error_Row_selfie_Function(str_text) \n",
        "          except json.decoder.JSONDecodeError:\n",
        "            raise          \n",
        "          try:\n",
        "            loan_amount_col.append(loan_error.get('loan_amount'))           \n",
        "          except AttributeError:\n",
        "            loan_amount_col.append(None)\n",
        "          try:\n",
        "            loan_purpose_col.append(loan_error.get('loan_purpose'))              \n",
        "          except AttributeError:\n",
        "            loan_purpose_col.append(None)\n",
        "          try:\n",
        "            product_col.append(loan_error.get('product'))\n",
        "          except AttributeError:\n",
        "            product_col.append(None)\n",
        "          try:\n",
        "            tenor_col.append(loan_error.get('tenor'))\n",
        "          except AttributeError:\n",
        "            tenor_col.append(None)\n",
        "          try:\n",
        "            tenor_type_col.append(loan_error.get('tenor_type'))\n",
        "          except AttributeError:\n",
        "            tenor_type_col.append(None)            \n",
        "          \n",
        "          error_code_col.append(None)\n",
        "          error_number_col.append(None)\n",
        "          error_sql_message_col.append(None)\n",
        "          error_sql_state_col.append(None)\n",
        "          error_index_col.append(None)\n",
        "          error_sql_col.append(None)  \n",
        "          error_userID_col.append(None)\n",
        "          error_status_col.append(None) \n",
        "          error_request_col.append(None)  \n",
        "          error_rate_col.append(None)\n",
        "          error_name_col.append(None)\n",
        "          error_date_created_col.append(None)\n",
        "          error_creator_type_col.append(None)\n",
        "          error_created_by_col.append(None)    \n",
        "      else:     \n",
        "        try:\n",
        "          loan_error = parse_Error_Row_selfie_INSERT_INTO_Function(str_text) \n",
        "          #print(loan_error)\n",
        "        except json.decoder.JSONDecodeError:\n",
        "          raise\n",
        "        loan_amount_col.append(None)\n",
        "        loan_purpose_col.append(None)\n",
        "        product_col.append(None)\n",
        "        tenor_col.append(None)\n",
        "        tenor_type_col.append(None)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)\n",
        "        try:\n",
        "          type_request_col.append(type_of_request.group(0))\n",
        "        except AttributeError:\n",
        "          type_request_col.append(None)\n",
        "        try:\n",
        "          error_code_col.append(loan_error.get('code'))\n",
        "        except AttributeError:\n",
        "          error_code_col.append(None)\n",
        "        try:\n",
        "          error_number_col.append(loan_error.get('errno'))\n",
        "        except AttributeError:\n",
        "          error_number_col.append(None)\n",
        "        try:\n",
        "          error_sql_message_col.append(loan_error.get('sqlMessage'))\n",
        "        except AttributeError:\n",
        "          error_sql_message_col.append(None)\n",
        "        try:\n",
        "          error_sql_state_col.append(loan_error.get('sqlState'))\n",
        "        except AttributeError:\n",
        "          error_sql_state_col.append(None)\n",
        "        try:\n",
        "          error_created_by_col.append(loan_error.get('created_by'))\n",
        "        except AttributeError:\n",
        "          error_created_by_col.append(None)\n",
        "        try:\n",
        "          error_creator_type_col.append(loan_error.get('creator_type'))\n",
        "        except AttributeError:\n",
        "          error_creator_type_col.append(None)\n",
        "        try:\n",
        "          error_date_created_col.append(loan_error.get('date_created'))\n",
        "        except AttributeError:\n",
        "          error_date_created_col.append(None)\n",
        "        try:\n",
        "          error_sql_col.append(loan_error.get('sql'))\n",
        "        except AttributeError:\n",
        "          error_sql_col.append(None)\n",
        "        try:\n",
        "          error_name_col.append(loan_error.get('name'))\n",
        "        except AttributeError:\n",
        "          error_name_col.append(None)\n",
        "        try:\n",
        "          error_rate_col.append(loan_error.get('rate'))\n",
        "        except AttributeError:\n",
        "          error_rate_col.append(None)\n",
        "        try:\n",
        "          error_index_col.append(loan_error.get('index'))\n",
        "        except AttributeError:\n",
        "          error_index_col.append(None)\n",
        "        try:\n",
        "          error_request_col.append(loan_error.get('request'))\n",
        "        except AttributeError:\n",
        "          error_request_col.append(None)\n",
        "        try:\n",
        "          error_status_col.append(loan_error.get('status'))\n",
        "        except AttributeError:\n",
        "          error_status_col.append(None)\n",
        "        try:\n",
        "          error_userID_col.append(loan_error.get('userID'))\n",
        "        except AttributeError:\n",
        "          error_userID_col.append(None)\n",
        "\n",
        "  df_['Type_Request'] = type_request_col\n",
        "  df_['Log_Level'] = log_level_col\n",
        "  df_['Error Code'] = error_code_col\n",
        "  df_['Error Number'] = error_number_col\n",
        "  df_['Error Sql Message'] = error_sql_message_col\n",
        "  df_['Error Sql State'] = error_sql_state_col\n",
        "  df_['Error Index'] = error_index_col\n",
        "  df_['Error Sql'] = error_sql_col\n",
        "  df_['Loan Amount'] = loan_amount_col\n",
        "  df_['Loan Purpose'] = loan_purpose_col\n",
        "  df_['Product'] = product_col\n",
        "  df_['Tenor'] = tenor_col\n",
        "  df_['Tenor Type'] = tenor_type_col\n",
        "  df_['Error created by'] = error_created_by_col\n",
        "  df_['Error creator Type'] = error_creator_type_col \n",
        "  df_['Error Date created'] = error_date_created_col\n",
        "  df_['Error Name'] = error_name_col\n",
        "  df_['Error Rate'] = error_rate_col\n",
        "  df_['Error Request'] = error_request_col\n",
        "  df_['Error Status'] = error_status_col\n",
        "  df_['Error UserID'] = error_userID_col\n",
        "\n",
        "\n",
        "  return df_"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUFaAC7BtJbh"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "error = df_raw[df_raw['text'].str.contains('LOAN ERROR')]\n",
        "df_error = parse_row_error(error)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQowf3DowAM"
      },
      "source": [
        "df_error.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O9Ghnbls4hN"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_api_request(df_api_request):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_api_request = []\n",
        "  list_column_none_api_request = [message_sms_payload_col, totalsent_col, cost_col, status_col,\n",
        "                                  bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, account_number_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_api_request.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)        \n",
        "        # check if the row contains an email address \n",
        "        # pour tous les types request créer un dictionnaire dans lequel mapper\n",
        "        # key = type de request et value = les regex définis\n",
        "        # pour chaque condition IF créer une liste de colonnes auxquelles affecter None\n",
        "        if 'mailto' in str_text:\n",
        "            if re.search('API REQUEST', str_text):\n",
        "                type_of_request = re.search('API REQUEST', str_text)                \n",
        "                phone_or_email_api_req = re.search(type_request_dictionnary['API REQUEST'][0], str_text)                              \n",
        "                endpoint = re.search(type_request_dictionnary['API REQUEST'][1], str_text)\n",
        "                pattern = type_request_dictionnary['API REQUEST'][2]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for i in range(len(list_column_none_api_request)):\n",
        "                  list_column_none_api_request[i].append(None)\n",
        "                               \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0)) # add type request inside type request column\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)               \n",
        "                try:\n",
        "                  email_col.append(phone_or_email_api_req.group(0)) # add email inside email column\n",
        "                  phone_Col.append(None)  # in this case there is no phone number\n",
        "                except AttributeError:\n",
        "                  email_col.append(None)\n",
        "                try:\n",
        "                  endpoint_col.append(endpoint.group(0)) # add endpoint inside endpoint column\n",
        "                except AttributeError:\n",
        "                  endpoint_col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None)\n",
        "              \n",
        "\n",
        "        elif 'mailto' not in str_text:\n",
        "            if re.search('API REQUEST', str_text):\n",
        "                type_of_request = re.search('API REQUEST', str_text)                            \n",
        "                # extract a phone number for API REQUEST\n",
        "                phone_or_email_api_req = re.search(type_request_dictionnary['API REQUEST'][3], str_text)                              \n",
        "                endpoint = re.search(type_request_dictionnary['API REQUEST'][1], str_text)\n",
        "                pattern = type_request_dictionnary['API REQUEST'][2]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for i in range(len(list_column_none_api_request)):\n",
        "                  list_column_none_api_request[i].append(None)\n",
        "\n",
        "                try:\n",
        "                  phone_Col.append(phone_or_email_api_req.group(0)) # add phone number inside phone number column\n",
        "                  email_col.append(None) # in this case there is no email address\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  endpoint_col.append(endpoint.group(0)) # add endpoint inside endpoint column\n",
        "                except AttributeError:\n",
        "                  endpoint_col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None)\n",
        "\n",
        "  df_api_request['Type_Request'] = type_request_col\n",
        "  df_api_request['Phone_Number'] = phone_Col\n",
        "  df_api_request['Date'] = date_col\n",
        "  df_api_request['EndPoint'] = endpoint_col\n",
        "  df_api_request['Log_Level'] = log_level_col\n",
        "  df_api_request['Email'] = email_col\n",
        "  df_api_request['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_api_request['Total Sent'] = totalsent_col\n",
        "  df_api_request['Cost'] = cost_col\n",
        "  df_api_request['Status'] = status_col\n",
        "  df_api_request['Account Number'] = account_number_col\n",
        "  df_api_request['Account Name'] = account_name_col\n",
        "  df_api_request['BVN'] = bvn_col\n",
        "  df_api_request['Request Successful'] = requestSuccessful_col\n",
        "  df_api_request['Response Message'] = responseMessage_col\n",
        "  df_api_request['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_api_request"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWb_8xSS8-wo"
      },
      "source": [
        ""
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XIIds-DtBOP"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "api_request = df_raw[df_raw['text'].str.contains('API REQUEST')]\n",
        "df_api_request = parse_row_api_request(api_request)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxpM-PLFj_cK"
      },
      "source": [
        "df_api_request.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj661cCus7YS"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_client_mobile_login(df_client_mob):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_client_mobile = []\n",
        "  list_column_none_client_mobile = [message_sms_payload_col, totalsent_col, cost_col, status_col,\n",
        "                                  account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, endpoint_Col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_client_mob.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)        \n",
        "        # check if the row contains an email address \n",
        "        # pour tous les types request créer un dictionnaire dans lequel mapper\n",
        "        # key = type de request et value = les regex définis\n",
        "        # pour chaque condition IF créer une liste de colonnes auxquelles affecter None\n",
        "        if 'mailto' in str_text:\n",
        "            if re.search('CLIENT MOBILE LOGIN', str_text):   # CLIENT MOBILE LOGIN with email address\n",
        "                  type_of_request = re.search('CLIENT MOBILE LOGIN', str_text)\n",
        "                  # extract address email for CLIENT MOBILE LOGIN\n",
        "                  phone_or_email_client_mobile = re.search(type_request_dictionnary['CLIENT MOBILE LOGIN'][0], str_text)                               \n",
        "                  pattern = type_request_dictionnary['CLIENT MOBILE LOGIN'][1]\n",
        "                  datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                  datematcher = datepattern.search(str_text)  # extract date for CLIENT MOBILE LOGIN type request\n",
        "                  \n",
        "                  for j in range(len(list_column_none_client_mobile)):\n",
        "                    list_column_none_client_mobile[j].append(None)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0)) # add type request inside type request column\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None) \n",
        "                  try:\n",
        "                    email_col.append(phone_or_email_client_mobile.group(0)) # add email inside email column\n",
        "                    phone_Col.append(None)  # in this case there is no phone number\n",
        "                  except AttributeError:\n",
        "                    email_col.append(None)\n",
        "                  try:\n",
        "                    date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                  except AttributeError:\n",
        "                    date_col.append(None)\n",
        "\n",
        "        elif 'mailto' not in str_text:\n",
        "            if re.search('CLIENT MOBILE LOGIN', str_text): # when type request is CLIENT MOBILE LOGIN, there is no EndPoint\n",
        "                type_of_request = re.search('CLIENT MOBILE LOGIN', str_text)\n",
        "                # extract a phone number for CLIENT MOBILE LOGIN\n",
        "                phone_or_email_client_mobile = re.search(type_request_dictionnary['CLIENT MOBILE LOGIN'][2], str_text)                  \n",
        "                pattern = type_request_dictionnary['CLIENT MOBILE LOGIN'][1]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for j in range(len(list_column_none_client_mobile)):\n",
        "                    list_column_none_client_mobile[j].append(None)\n",
        "\n",
        "                try:\n",
        "                  phone_Col.append(phone_or_email_client_mobile.group(0))\n",
        "                  email_col.append(None)\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None) \n",
        "\n",
        "  df_client_mob['Type_Request'] = type_request_col\n",
        "  df_client_mob['Phone_Number'] = phone_Col\n",
        "  df_client_mob['Date'] = date_col\n",
        "  df_client_mob['EndPoint'] = endpoint_Col\n",
        "  df_client_mob['Log_Level'] = log_level_col\n",
        "  df_client_mob['Email'] = email_col\n",
        "  df_client_mob['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_client_mob['Total Sent'] = totalsent_col\n",
        "  df_client_mob['Cost'] = cost_col\n",
        "  df_client_mob['Status'] = status_col\n",
        "  df_client_mob['Account Number'] = account_number_col\n",
        "  df_client_mob['Account Name'] = account_name_col\n",
        "  df_client_mob['BVN'] = bvn_col\n",
        "  df_client_mob['Request Successful'] = requestSuccessful_col\n",
        "  df_client_mob['Response Message'] = responseMessage_col\n",
        "  df_client_mob['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_client_mob"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnqWyhXp3U-5"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "client_mobile_login = df_raw[df_raw['text'].str.contains('CLIENT MOBILE LOGIN')]\n",
        "df_client_mobile_login = parse_row_client_mobile_login(client_mobile_login)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSzleZV-3t3Z"
      },
      "source": [
        "df_client_mobile_login.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpBB-0cg3hAG"
      },
      "source": [
        "Handle DataFrame for SMS PAYLOAD Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XVntz9o3mbD"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_sms_payload_function(df_sms_payload):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  \n",
        "  list_column_none_sms_payload = []\n",
        "  list_column_none_sms_payload = [totalsent_col, cost_col, status_col,\n",
        "                                  account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, email_col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_sms_payload.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('SMS PAYLOAD', str_text):\n",
        "                type_of_request = re.search('SMS PAYLOAD', str_text)            \n",
        "                sms_payload = parse_wallet_sms_payload_success(str_text)               \n",
        "                for l in range(len(list_column_none_sms_payload)):\n",
        "                    list_column_none_sms_payload[l].append(None)             \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  phone_Col.append(sms_payload.get('phone'))\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  message_sms_payload_col.append(sms_payload.get('message'))\n",
        "                except AttributeError:\n",
        "                  message_sms_payload_col.append(None)\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "  df_sms_payload['Type_Request'] = type_request_col\n",
        "  df_sms_payload['Phone_Number'] = phone_Col\n",
        "  df_sms_payload['Date'] = date_col\n",
        "  df_sms_payload['EndPoint'] = endpoint_Col\n",
        "  df_sms_payload['Log_Level'] = log_level_col\n",
        "  df_sms_payload['Email'] = email_col\n",
        "  df_sms_payload['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_sms_payload['Total Sent'] = totalsent_col\n",
        "  df_sms_payload['Cost'] = cost_col\n",
        "  df_sms_payload['Status'] = status_col\n",
        "  df_sms_payload['Account Number'] = account_number_col\n",
        "  df_sms_payload['Account Name'] = account_name_col\n",
        "  df_sms_payload['BVN'] = bvn_col\n",
        "  df_sms_payload['Request Successful'] = requestSuccessful_col\n",
        "  df_sms_payload['Response Message'] = responseMessage_col\n",
        "  df_sms_payload['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_sms_payload\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOM6gkyh3-B0"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "sms_payload = df_raw[df_raw['text'].str.contains('SMS PAYLOAD')]\n",
        "df_sms_payload = parse_row_sms_payload_function(sms_payload)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzrdhU6Kkbat"
      },
      "source": [
        "df_sms_payload.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrJjMbac4HGd"
      },
      "source": [
        "Handle DataFrame for SMS Success Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD8J_KpN4H7J"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_sms_success_function(df_sms_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  \n",
        "  list_column_none_sms_success = []\n",
        "  list_column_none_sms_success = [message_sms_payload_col, account_number_col, bvn_col, requestSuccessful_col, \n",
        "                                  responseMessage_col, responseCode_col, account_name_col, email_col, \n",
        "                                  phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_sms_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('SMS SUCCESS', str_text): \n",
        "                type_of_request = re.search('SMS SUCCESS', str_text)\n",
        "                sms_success = parse_wallet_sms_payload_success(str_text)                \n",
        "                for m in range(len(list_column_none_sms_success)):\n",
        "                    list_column_none_sms_success[m].append(None) \n",
        "           \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:                 \n",
        "                  totalsent_col.append(sms_success.get('response').get('totalsent '))\n",
        "                except AttributeError:\n",
        "                  totalsent_col.append(None)\n",
        "                try:                 \n",
        "                  cost_col.append(sms_success.get('response').get('cost '))\n",
        "                except AttributeError:\n",
        "                  cost_col.append(None)\n",
        "                try:                 \n",
        "                  status_col.append(sms_success.get('response').get('status '))\n",
        "                except AttributeError:\n",
        "                  status_col.append(None)\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)    \n",
        "\n",
        "  df_sms_success['Type_Request'] = type_request_col\n",
        "  df_sms_success['Phone_Number'] = phone_Col\n",
        "  df_sms_success['Date'] = date_col\n",
        "  df_sms_success['EndPoint'] = endpoint_Col\n",
        "  df_sms_success['Log_Level'] = log_level_col\n",
        "  df_sms_success['Email'] = email_col\n",
        "  df_sms_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_sms_success['Total Sent'] = totalsent_col\n",
        "  df_sms_success['Cost'] = cost_col\n",
        "  df_sms_success['Status'] = status_col\n",
        "  df_sms_success['Account Number'] = account_number_col\n",
        "  df_sms_success['Account Name'] = account_name_col\n",
        "  df_sms_success['BVN'] = bvn_col\n",
        "  df_sms_success['Request Successful'] = requestSuccessful_col\n",
        "  df_sms_success['Response Message'] = responseMessage_col\n",
        "  df_sms_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_sms_success\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_Z6cSQ4Ou9"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "sms_success = df_raw[df_raw['text'].str.contains('SMS SUCCESS')]\n",
        "df_sms_success = parse_row_sms_success_function(sms_success)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMY6oNKUkoPE"
      },
      "source": [
        "df_sms_success.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgN9dHMi4WhI"
      },
      "source": [
        "Handle DataFrame for WALLET SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqjCjokx4X-5"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_wallet_success_function(df_wallet_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  message_error_col = []\n",
        "\n",
        "  list_column_none_wallet_success = []\n",
        "  list_column_none_wallet_success = [totalsent_col, message_sms_payload_col, cost_col, status_col, \n",
        "                                     email_col, phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "  \n",
        "  for index, row in df_wallet_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)\n",
        "\n",
        "        if re.search('WALLET SUCCESS', str_text):\n",
        "            type_of_request = re.search('WALLET SUCCESS', str_text)           \n",
        "\n",
        "            if 'Faithfully yours, nginx' in str_text:\n",
        "                error_text = 'Sorry, the page you are looking for is currently unavailable, Please try again later.'\n",
        "                message_error_col.append(error_text)\n",
        "                type_request_col.append(type_of_request.group(0))\n",
        "                account_number_col.append(None)\n",
        "                account_name_col.append(None)\n",
        "                bvn_col.append(None)\n",
        "                requestSuccessful_col.append(None)\n",
        "                responseMessage_col.append(None)\n",
        "                responseCode_col.append(None)\n",
        "            else:\n",
        "                try:\n",
        "                  wallet_success = parse_providus_transfer_error_function(str_text)\n",
        "                except json.decoder.JSONDecodeError:\n",
        "                  #print(str_text)\n",
        "                  raise\n",
        "                message_error_col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  account_number_col.append(wallet_success.get('account_number'))\n",
        "                except AttributeError:\n",
        "                  account_number_col.append(None)\n",
        "                try:\n",
        "                  account_name_col.append(wallet_success.get('account_name'))\n",
        "                except AttributeError:\n",
        "                  account_name_col.append(None)\n",
        "                try:\n",
        "                  bvn_col.append(wallet_success.get('bvn'))\n",
        "                except AttributeError:\n",
        "                  bvn_col.append(None)\n",
        "                try:\n",
        "                  requestSuccessful_col.append(wallet_success.get('requestSuccessful'))\n",
        "                except AttributeError:\n",
        "                  requestSuccessful_col.append(None)\n",
        "                try:\n",
        "                  responseMessage_col.append((wallet_success.get('responseMessage')))\n",
        "                except AttributeError:\n",
        "                  responseMessage_col.append(None)\n",
        "                try:\n",
        "                  responseCode_col.append((wallet_success.get('responseCode')))\n",
        "                except AttributeError:\n",
        "                  responseCode_col.append(None)\n",
        "\n",
        "            for n in range(len(list_column_none_wallet_success)):\n",
        "              list_column_none_wallet_success[n].append(None) \n",
        "\n",
        "                       \n",
        "\n",
        "  df_wallet_success['Type_Request'] = type_request_col\n",
        "  df_wallet_success['Phone_Number'] = phone_Col\n",
        "  df_wallet_success['Date'] = date_col\n",
        "  df_wallet_success['EndPoint'] = endpoint_Col\n",
        "  df_wallet_success['Log_Level'] = log_level_col\n",
        "  df_wallet_success['Email'] = email_col\n",
        "  df_wallet_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_wallet_success['Total Sent'] = totalsent_col\n",
        "  df_wallet_success['Cost'] = cost_col\n",
        "  df_wallet_success['Status'] = status_col\n",
        "  df_wallet_success['Account Number'] = account_number_col\n",
        "  df_wallet_success['Account Name'] = account_name_col\n",
        "  df_wallet_success['BVN'] = bvn_col\n",
        "  df_wallet_success['Request Successful'] = requestSuccessful_col\n",
        "  df_wallet_success['Response Message'] = responseMessage_col\n",
        "  df_wallet_success['Response Code'] = responseCode_col\n",
        "  df_wallet_success['Error Message Wallet'] = message_error_col\n",
        " \n",
        "  return df_wallet_success"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnoeVazJ4fZE"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "wallet_success = df_raw[df_raw['text'].str.contains('WALLET SUCCESS')]\n",
        "df_wallet_success = parse_row_wallet_success_function(wallet_success)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5NWvVoga5r-"
      },
      "source": [
        "df_wallet_success.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xYItsxk8Ion"
      },
      "source": [
        "### Handle DataFrame for OKRA WEBHOOK Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ2J1GQ88N4b"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_okra_webhook_function(df_okra):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  accountId_col = []\n",
        "  authorization_v_col = []\n",
        "  authorization_id_col = []\n",
        "  authorization_customer_col = []\n",
        "  authorization_account_col = []\n",
        "  authorization_account_id_col = []\n",
        "  authorization_account_manual_col = []\n",
        "  authorization_account_name_col = []\n",
        "  authorization_account_nuban_col = []\n",
        "  authorization_account_bank_col = []\n",
        "  authorization_account_created_at_col = []\n",
        "  authorization_account_last_updated_col = []\n",
        "  authorization_account_balance_col = []\n",
        "  authorization_account_customer_col = []\n",
        "  authorization_account_type_col = []\n",
        "  authorization_account_currency_col = []\n",
        "  authorization_accounts_col = []\n",
        "  authorization_amount_col = []\n",
        "  authorization_bank_col = []\n",
        "  authorization_created_at_col = []\n",
        "  authorization_currency_col = []\n",
        "  authorization_customerDetails_col = []\n",
        "  authorization_disconnect_col = []\n",
        "  authorization_disconnected_at_col = []\n",
        "  authorization_duration_col = []\n",
        "  authorization_env_col = []\n",
        "  authorization_garnish_col = []\n",
        "  authorization_initialAmount_col = []\n",
        "  authorization_initiated_col = []\n",
        "  authorization_last_updated_col = []\n",
        "  authorization_link_col = []\n",
        "  authorization_next_payment_col = []\n",
        "  authorization_owner_col = []\n",
        "  authorization_payLink_col = []\n",
        "  authorization_type_col = []\n",
        "  authorization_used_col = []\n",
        "  authorizationId_col = []\n",
        "  bankId_col = []\n",
        "  bankName_col = []\n",
        "  bankSlug_col = []\n",
        "  bankType_col = []\n",
        "  callbackURL_col = []\n",
        "  callback_code_col = []\n",
        "  callback_type_col = []\n",
        "  callback_url_col = []\n",
        "  code_col = []\n",
        "  country_col = []\n",
        "  current_project_col = []\n",
        "  customerEmail_col = []\n",
        "  customerId_col = []\n",
        "  ended_at_col = []\n",
        "  env_col = []\n",
        "  extras_col = []\n",
        "  identityType_col = []\n",
        "  login_type_col = []\n",
        "  message_col = []\n",
        "  meta_col = []\n",
        "  method_col = []\n",
        "  options_col = []\n",
        "  owner_col = []\n",
        "  record_col = []\n",
        "  recordId_col = []\n",
        "  started_at_col = []\n",
        "  status_webhook_col = []\n",
        "  token_col = []\n",
        "  type_col = []\n",
        "\n",
        "  list_column_none_okra_webhook = []\n",
        "  list_column_none_okra_webhook = [api_request_col, account_number_col, account_name_col, totalsent_col, \n",
        "                                   message_sms_payload_col, cost_col, status_col, responseCode_col,\n",
        "                                   bvn_col, requestSuccessful_col, responseMessage_col, email_col, phone_Col, \n",
        "                                   endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_okra.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('OKRA WEBHOOK', str_text):\n",
        "                  type_of_request = re.search('OKRA WEBHOOK', str_text)\n",
        "                  okra_webhook = parse_wallet_sms_payload_success(str_text) \n",
        "                  if 'authorization' in str_text:\n",
        "                      accountId_col.append(okra_webhook.get('accountId'))\n",
        "                      authorization_v_col.append(okra_webhook.get('authorization').get('__v '))\n",
        "                      authorization_id_col.append(okra_webhook.get('authorization').get('_id '))\n",
        "                      authorization_customer_col.append(okra_webhook.get('authorization').get('customer '))\n",
        "                      authorization_account_col.append(okra_webhook.get('authorization').get('account '))\n",
        "                      authorization_account_id_col.append(okra_webhook.get('authorization').get('account ')[0].get('_id '))\n",
        "                      authorization_account_manual_col.append(okra_webhook.get('authorization').get('account ')[0].get('manual '))\n",
        "                      authorization_account_name_col.append(okra_webhook.get('authorization').get('account ')[0].get('name '))\n",
        "                      authorization_account_nuban_col.append(okra_webhook.get('authorization').get('account ')[0].get('nuban '))\n",
        "                      authorization_account_bank_col.append(okra_webhook.get('authorization').get('account ')[0].get('bank '))\n",
        "                      authorization_account_created_at_col.append(okra_webhook.get('authorization').get('account ')[0].get('created_at '))\n",
        "                      authorization_account_last_updated_col.append(okra_webhook.get('authorization').get('account ')[0].get('last_updated '))\n",
        "                      authorization_account_balance_col.append(okra_webhook.get('authorization').get('account ')[0].get('balance '))\n",
        "                      authorization_account_customer_col.append(okra_webhook.get('authorization').get('account ')[0].get('customer '))\n",
        "                      authorization_account_type_col.append(okra_webhook.get('authorization').get('account ')[0].get('type '))\n",
        "                      authorization_account_currency_col.append(okra_webhook.get('authorization').get('account ')[0].get('currency '))\n",
        "                      authorization_accounts_col.append(okra_webhook.get('authorization').get('accounts '))\n",
        "                      authorization_amount_col.append(okra_webhook.get('authorization').get('amount '))\n",
        "                      authorization_bank_col.append(okra_webhook.get('authorization').get('bank '))\n",
        "                      authorization_created_at_col.append(okra_webhook.get('authorization').get('created_at '))\n",
        "                      authorization_currency_col.append(okra_webhook.get('authorization').get('currency '))\n",
        "                      authorization_customerDetails_col.append(okra_webhook.get('authorization').get('customerDetails '))\n",
        "                      authorization_disconnect_col.append(okra_webhook.get('authorization').get('disconnect '))\n",
        "                      authorization_disconnected_at_col.append(okra_webhook.get('authorization').get('disconnected_at '))\n",
        "                      authorization_duration_col.append(okra_webhook.get('authorization').get('duration '))\n",
        "                      authorization_env_col.append(okra_webhook.get('authorization').get('env '))\n",
        "                      authorization_garnish_col.append(okra_webhook.get('authorization').get('garnish '))\n",
        "                      authorization_initialAmount_col.append(okra_webhook.get('authorization').get('initialAmount '))\n",
        "                      authorization_initiated_col.append(okra_webhook.get('authorization').get('initiated '))\n",
        "                      authorization_last_updated_col.append(okra_webhook.get('authorization').get('last_updated '))\n",
        "                      authorization_link_col.append(okra_webhook.get('authorization').get('link '))\n",
        "                      authorization_next_payment_col.append(okra_webhook.get('authorization').get('next_payment '))\n",
        "                      authorization_owner_col.append(okra_webhook.get('authorization').get('owner '))\n",
        "                      authorization_payLink_col.append(okra_webhook.get('authorization').get('payLink '))\n",
        "                      authorization_type_col.append(okra_webhook.get('authorization').get('type '))\n",
        "                      authorization_used_col.append(okra_webhook.get('authorization').get('used '))\n",
        "                      authorizationId_col.append(None)\n",
        "                      bankId_col.append(None)\n",
        "                      bankName_col.append(None)\n",
        "                      bankSlug_col.append(None)\n",
        "                      bankType_col.append(None)\n",
        "                      callbackURL_col.append(None)\n",
        "                      callback_code_col.append(None)\n",
        "                      callback_type_col.append(None)\n",
        "                      callback_url_col.append(None)\n",
        "                      code_col.append(None)\n",
        "                      country_col.append(None)\n",
        "                      current_project_col.append(None)\n",
        "                      customerEmail_col.append(None)\n",
        "                      customerId_col.append(None)\n",
        "                      ended_at_col.append(None)\n",
        "                      env_col.append(None)\n",
        "                      extras_col.append(None)\n",
        "                      identityType_col.append(None)\n",
        "                      login_type_col.append(None)\n",
        "                      message_col.append(None)\n",
        "                      meta_col.append(None)\n",
        "                      method_col.append(None)\n",
        "                      options_col.append(None)\n",
        "                      owner_col.append(None)\n",
        "                      record_col.append(None)\n",
        "                      recordId_col.append(None)\n",
        "                      started_at_col.append(None)\n",
        "                      status_webhook_col.append(None)\n",
        "                      token_col.append(None)\n",
        "                      type_col.append(None)\n",
        "                      try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                      except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                  else:\n",
        "                      authorizationId_col.append(okra_webhook.get('authorizationId'))\n",
        "                      bankId_col.append(okra_webhook.get('bankId'))\n",
        "                      bankName_col.append(okra_webhook.get('bankName'))\n",
        "                      bankSlug_col.append(okra_webhook.get('bankSlug'))\n",
        "                      bankType_col.append(okra_webhook.get('bankType'))\n",
        "                      callbackURL_col.append(okra_webhook.get('callbackURL'))\n",
        "                      callback_code_col.append(okra_webhook.get('callback_code'))\n",
        "                      callback_type_col.append(okra_webhook.get('callback_type'))\n",
        "                      callback_url_col.append(okra_webhook.get('callback_url'))\n",
        "                      code_col.append(okra_webhook.get('code'))\n",
        "                      country_col.append(okra_webhook.get('country'))\n",
        "                      current_project_col.append(okra_webhook.get('current_project'))\n",
        "                      customerEmail_col.append(okra_webhook.get('customerEmail'))\n",
        "                      customerId_col.append(okra_webhook.get('customerId'))\n",
        "                      ended_at_col.append(okra_webhook.get('ended_at'))\n",
        "                      env_col.append(okra_webhook.get('env'))\n",
        "                      extras_col.append(okra_webhook.get('extras'))\n",
        "                      identityType_col.append(okra_webhook.get('identityType'))\n",
        "                      login_type_col.append(okra_webhook.get('login_type'))\n",
        "                      message_col.append(okra_webhook.get('message'))\n",
        "                      meta_col.append(okra_webhook.get('meta'))\n",
        "                      method_col.append(okra_webhook.get('method'))\n",
        "                      options_col.append(okra_webhook.get('options'))\n",
        "                      owner_col.append(okra_webhook.get('owner'))\n",
        "                      record_col.append(okra_webhook.get('record'))\n",
        "                      recordId_col.append(okra_webhook.get('recordId'))\n",
        "                      started_at_col.append(okra_webhook.get('started_at'))\n",
        "                      status_webhook_col.append(okra_webhook.get('status'))\n",
        "                      token_col.append(okra_webhook.get('token'))\n",
        "                      type_col.append(okra_webhook.get('type'))\n",
        "                      accountId_col.append(None)\n",
        "                      authorization_v_col.append(None)\n",
        "                      authorization_id_col.append(None)\n",
        "                      authorization_customer_col.append(None)\n",
        "                      authorization_account_col.append(None)\n",
        "                      authorization_account_id_col.append(None)\n",
        "                      authorization_account_manual_col.append(None)\n",
        "                      authorization_account_name_col.append(None)\n",
        "                      authorization_account_nuban_col.append(None)\n",
        "                      authorization_account_bank_col.append(None)\n",
        "                      authorization_account_created_at_col.append(None)\n",
        "                      authorization_account_last_updated_col.append(None)\n",
        "                      authorization_account_balance_col.append(None)\n",
        "                      authorization_account_customer_col.append(None)\n",
        "                      authorization_account_type_col.append(None)\n",
        "                      authorization_account_currency_col.append(None)\n",
        "                      authorization_accounts_col.append(None)\n",
        "                      authorization_amount_col.append(None)\n",
        "                      authorization_bank_col.append(None)\n",
        "                      authorization_created_at_col.append(None)\n",
        "                      authorization_currency_col.append(None)\n",
        "                      authorization_customerDetails_col.append(None)\n",
        "                      authorization_disconnect_col.append(None)\n",
        "                      authorization_disconnected_at_col.append(None)\n",
        "                      authorization_duration_col.append(None)\n",
        "                      authorization_env_col.append(None)\n",
        "                      authorization_garnish_col.append(None)\n",
        "                      authorization_initialAmount_col.append(None)\n",
        "                      authorization_initiated_col.append(None)\n",
        "                      authorization_last_updated_col.append(None)\n",
        "                      authorization_link_col.append(None)\n",
        "                      authorization_next_payment_col.append(None)\n",
        "                      authorization_owner_col.append(None)\n",
        "                      authorization_payLink_col.append(None)\n",
        "                      authorization_type_col.append(None)\n",
        "                      authorization_used_col.append(None)\n",
        "                      try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                      except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                  \n",
        "                  for n in range(len(list_column_none_okra_webhook)):\n",
        "                    list_column_none_okra_webhook[n].append(None) \n",
        "\n",
        "       \n",
        "  df_okra['Type_Request'] = type_request_col\n",
        "  df_okra['Phone_Number'] = phone_Col\n",
        "  df_okra['Date'] = date_col\n",
        "  df_okra['EndPoint'] = endpoint_Col\n",
        "  df_okra['Log_Level'] = log_level_col\n",
        "  df_okra['Email'] = email_col\n",
        "  df_okra['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_okra['Total Sent'] = totalsent_col\n",
        "  df_okra['Cost'] = cost_col\n",
        "  df_okra['Status'] = status_col\n",
        "  df_okra['Account Number'] = account_number_col\n",
        "  df_okra['Account Name'] = account_name_col\n",
        "  df_okra['BVN'] = bvn_col\n",
        "  df_okra['Request Successful'] = requestSuccessful_col\n",
        "  df_okra['Response Message'] = responseMessage_col\n",
        "  df_okra['Response Code'] = responseCode_col\n",
        "  df_okra['Account Id'] = accountId_col\n",
        "  df_okra['Authorization_V'] = authorization_v_col\n",
        "  df_okra['Authorization_Id'] = authorization_id_col\n",
        "  df_okra['Authorization_Customer'] = authorization_customer_col\n",
        "  df_okra['Authorization_Owner'] = authorization_owner_col\n",
        "  df_okra['Authorization_Account'] = authorization_account_col\n",
        "  df_okra['Authorization_account_Id'] = authorization_account_id_col\n",
        "  df_okra['Authorization_account_manual'] = authorization_account_manual_col\n",
        "  df_okra['Authorization_account_name'] = authorization_account_name_col\n",
        "  df_okra['Authorization_account_nuban'] = authorization_account_nuban_col\n",
        "  df_okra['Authorization_account_bank'] = authorization_account_bank_col\n",
        "  df_okra['Authorization_account_created_at'] = authorization_account_created_at_col\n",
        "  df_okra['Authorization_account_last_updated'] = authorization_account_last_updated_col\n",
        "  df_okra['Authorization_account_balance'] = authorization_account_balance_col\n",
        "  df_okra['Authorization_account_customer'] = authorization_account_customer_col\n",
        "  df_okra['Authorization_account_type'] = authorization_account_type_col\n",
        "  df_okra['Authorization_account_currency'] = authorization_account_currency_col\n",
        "  df_okra['Authorization_accounts'] = authorization_accounts_col\n",
        "  df_okra['Authorization_amount'] = authorization_amount_col\n",
        "  df_okra['Authorization_bank'] = authorization_bank_col\n",
        "  df_okra['Authorization_created_at'] = authorization_created_at_col\n",
        "  df_okra['Authorization_currency'] = authorization_currency_col \n",
        "  df_okra['Authorization_customerDetails'] = authorization_customerDetails_col\n",
        "  df_okra['Authorization_disconnect'] = authorization_disconnect_col\n",
        "  df_okra['Authorization_disconnected_at'] = authorization_disconnected_at_col\n",
        "  df_okra['Authorization_duration'] = authorization_duration_col\n",
        "  df_okra['Authorization_env'] = authorization_env_col\n",
        "  df_okra['Authorization_garnish'] = authorization_garnish_col\n",
        "  df_okra['Authorization_initialAmount'] = authorization_initialAmount_col\n",
        "  df_okra['Authorization_initiated'] = authorization_initiated_col\n",
        "  df_okra['Authorization_last_updated'] = authorization_last_updated_col\n",
        "  df_okra['Authorization_link'] = authorization_link_col\n",
        "  df_okra['Authorization_next_payment'] = authorization_next_payment_col\n",
        "  df_okra['Authorization_payLink'] = authorization_payLink_col\n",
        "  df_okra['Authorization_type'] = authorization_type_col\n",
        "  df_okra['Authorization_used'] = authorization_used_col\n",
        "  df_okra['AuthorizationId'] = authorizationId_col\n",
        "  df_okra['BankId'] = bankId_col\n",
        "  df_okra['BankName'] = bankName_col\n",
        "  df_okra['bankSlug'] = bankSlug_col\n",
        "  df_okra['bankType'] = bankType_col\n",
        "  df_okra['callbackURL'] = callbackURL_col\n",
        "  df_okra['callback_code'] = callback_code_col\n",
        "  df_okra['callback_type'] = callback_type_col \n",
        "  df_okra['callback_url'] = callback_url_col\n",
        "  df_okra['code'] = code_col\n",
        "  df_okra['country'] = country_col\n",
        "  df_okra['current_project'] = current_project_col\n",
        "  df_okra['customerEmail'] = customerEmail_col\n",
        "  df_okra['customerId'] = customerId_col\n",
        "  df_okra['ended_at'] = ended_at_col\n",
        "  df_okra['env'] = env_col\n",
        "  df_okra['extras'] = extras_col\n",
        "  df_okra['identityType'] = identityType_col\n",
        "  df_okra['login_type'] = login_type_col\n",
        "  df_okra['message'] = message_col\n",
        "  df_okra['meta'] = meta_col\n",
        "  df_okra['method'] = method_col\n",
        "  df_okra['options'] = options_col\n",
        "  df_okra['owner'] = owner_col\n",
        "  df_okra['record'] = record_col \n",
        "  df_okra['recordId'] = recordId_col\n",
        "  df_okra['started_at'] = started_at_col\n",
        "  df_okra['status_webhook'] = status_webhook_col\n",
        "  df_okra['token'] = token_col\n",
        "  df_okra['type'] = type_col\n",
        " \n",
        "  return df_okra\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uiWq1Np8Rxx"
      },
      "source": [
        "df_raw['text'].fillna('', inplace=True)\n",
        "df_okra_webhook = parse_row_okra_webhook_function(df_raw[df_raw['text'].str.contains('OKRA WEBHOOK')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBBybNxmhkfV"
      },
      "source": [
        "df_okra_webhook.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDihv11g8lnJ"
      },
      "source": [
        "Handle DataFrame for LEADWAY SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s46Md54R8phm"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_leadway_function(df_leadway_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_leadway_success = []\n",
        "  list_column_none_leadway_success = [message_sms_payload_col, totalsent_col, cost_col, status_col, \n",
        "                                     account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                     responseCode_col, account_name_col, email_col, phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_leadway_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('LEADWAY SUCCESS', str_text):\n",
        "                  type_of_request = re.search('LEADWAY SUCCESS', str_text)\n",
        "                  leadway_success_concat_text, index_first_succ, index_last_succ = parse_and_concatenate_Leadway_Success_Rows(df_)\n",
        "                  res_text_leadway = parse_Leadway_Success_Row(leadway_success_concat_text)\n",
        "                  for o in range(len(list_column_none_leadway_success)):\n",
        "                    list_column_none_leadway_success[o].append(None)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                   \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "  df_leadway_success['Type_Request'] = type_request_col\n",
        "  df_leadway_success['Phone_Number'] = phone_Col\n",
        "  df_leadway_success['Date'] = date_col\n",
        "  df_leadway_success['EndPoint'] = endpoint_Col\n",
        "  df_leadway_success['Log_Level'] = log_level_col\n",
        "  df_leadway_success['Email'] = email_col\n",
        "  df_leadway_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_leadway_success['Total Sent'] = totalsent_col\n",
        "  df_leadway_success['Cost'] = cost_col\n",
        "  df_leadway_success['Status'] = status_col\n",
        "  df_leadway_success['Account Number'] = account_number_col\n",
        "  df_leadway_success['Account Name'] = account_name_col\n",
        "  df_leadway_success['BVN'] = bvn_col\n",
        "  df_leadway_success['Request Successful'] = requestSuccessful_col\n",
        "  df_leadway_success['Response Message'] = responseMessage_col\n",
        "  df_leadway_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_leadway_success\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUIQgzNCcraR"
      },
      "source": [
        "Handle DataFrame for PROVIDUS PAYLOAD Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwSI2WLjFYyn"
      },
      "source": [
        "def parse_PROVIDUS_PAYLOAD_DF(df_providus_payload):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"PROVIDUS PAYLOAD\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    beneficiary_account_name_col = []\n",
        "    beneficiary_account_number_col = []\n",
        "    beneficiary_bank_col = []\n",
        "    currency_code_col = []\n",
        "    narration_col = []\n",
        "    source_account_name_col = []\n",
        "    transaction_amount_col = []\n",
        "    transaction_reference_col = []\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "\n",
        "    list_column_none_providus_payload = []\n",
        "    list_column_none_providus_payload = [totalsent_col, \n",
        "                                        message_sms_payload_col, \n",
        "                                        cost_col, \n",
        "                                        status_col, \n",
        "                                        email_col, \n",
        "                                        phone_col, \n",
        "                                        endpoint_col, \n",
        "                                        date_col,\n",
        "                                        account_number_col, account_name_col, bvn_col,\n",
        "                                        requestSuccessful_col, responseMessage_col,\n",
        "                                        responseCode_col]\n",
        "\n",
        "\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col,\n",
        "                    beneficiary_account_name_col, beneficiary_account_number_col, beneficiary_bank_col,\n",
        "                    currency_code_col, narration_col, source_account_name_col, transaction_amount_col,\n",
        "                    transaction_reference_col]\n",
        "\n",
        "    for index, row in df_providus_payload.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        # check if the row contains \"info\" string\n",
        "        if re.search('info', str_text):\n",
        "            log_level = re.search('info', str_text)\n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)             \n",
        "            if 'mailto' not in str_text:\n",
        "                if re.search('PROVIDUS PAYLOAD', str_text):               \n",
        "                    providus_payload = parse_wallet_sms_payload_success(str_text)\n",
        "                    type_of_request = re.search('PROVIDUS PAYLOAD', str_text)\n",
        "                       \n",
        "                    try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                    except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                    try:\n",
        "                        beneficiary_account_name_col.append(providus_payload.get('beneficiaryAccountName'))\n",
        "                    except AttributeError:\n",
        "                        beneficiary_account_name_col.append(None)\n",
        "                    try:\n",
        "                        beneficiary_account_number_col.append(providus_payload.get('beneficiaryAccountNumber'))\n",
        "                    except AttributeError:\n",
        "                        beneficiary_account_number_col.append(None)\n",
        "                    try:\n",
        "                        beneficiary_bank_col.append(providus_payload.get('beneficiaryBank'))\n",
        "                    except AttributeError:\n",
        "                        beneficiary_bank_col.append(None)\n",
        "                    try:\n",
        "                        currency_code_col.append(providus_payload.get('currencyCode'))\n",
        "                    except AttributeError:\n",
        "                        currency_code_col.append(None)\n",
        "                    try:\n",
        "                        narration_col.append((providus_payload.get('narration')))\n",
        "                    except AttributeError:\n",
        "                        narration_col.append(None)\n",
        "                    try:\n",
        "                        source_account_name_col.append((providus_payload.get('sourceAccountName')))\n",
        "                    except AttributeError:\n",
        "                        source_account_name_col.append(None)\n",
        "                    try:\n",
        "                        transaction_amount_col.append((providus_payload.get('transactionAmount')))\n",
        "                    except AttributeError:\n",
        "                        transaction_amount_col.append(None)\n",
        "                    try:\n",
        "                        transaction_reference_col.append((providus_payload.get('transactionReference')))\n",
        "                    except AttributeError:\n",
        "                        transaction_reference_col.append(None)\n",
        "\n",
        "                    for n in range(len(list_column_none_providus_payload)):\n",
        "                        list_column_none_providus_payload[n].append(None) \n",
        "              \n",
        "            elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "                type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "\n",
        "            elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "                type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "\n",
        "            elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "                type_of_request = re.search('VTPASS SUCCESS', str_text)\n",
        "\n",
        "   \n",
        "    df_providus_payload['Beneficiary_Account_Name'] = beneficiary_account_name_col\n",
        "    df_providus_payload['Beneficiary_Account_Number'] = beneficiary_account_number_col\n",
        "    df_providus_payload['Beneficiary_Bank'] = beneficiary_bank_col\n",
        "    df_providus_payload['Currency_Code'] = currency_code_col\n",
        "    df_providus_payload['Narration'] = narration_col\n",
        "    df_providus_payload['Source_Account_Name'] = source_account_name_col\n",
        "    df_providus_payload['Transaction_Amount'] = transaction_amount_col\n",
        "    df_providus_payload['Transaction_Reference'] = transaction_reference_col\n",
        "    df_providus_payload['Type_Request'] = type_request_col\n",
        "    df_providus_payload['Phone_Number'] = phone_col\n",
        "    df_providus_payload['Date'] = date_col\n",
        "    df_providus_payload['EndPoint'] = endpoint_col\n",
        "    df_providus_payload['Log_Level'] = log_level_col\n",
        "    df_providus_payload['Email'] = email_col\n",
        "    df_providus_payload['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_providus_payload['Total Sent'] = totalsent_col\n",
        "    df_providus_payload['Cost'] = cost_col\n",
        "    df_providus_payload['Status'] = status_col\n",
        "    df_providus_payload['Account Number'] = account_number_col\n",
        "    df_providus_payload['Account Name'] = account_name_col\n",
        "    df_providus_payload['BVN'] = bvn_col\n",
        "    df_providus_payload['Request Successful'] = requestSuccessful_col\n",
        "    df_providus_payload['Response Message'] = responseMessage_col\n",
        "    df_providus_payload['Response Code'] = responseCode_col\n",
        " \n",
        "    return df_providus_payload\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZo3IJz2Fc4S"
      },
      "source": [
        "providus_payload_df = df_raw[df_raw['text'].str.contains('PROVIDUS PAYLOAD')]\n",
        "df_providus_payload = parse_PROVIDUS_PAYLOAD_DF(providus_payload_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1vjwaKWiDYF"
      },
      "source": [
        "df_providus_payload.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4vA4j3kdCeX"
      },
      "source": [
        "Handle DataFrame for PROVIDUS SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEg3vA6Fc7Ym"
      },
      "source": [
        "def parse_PROVIDUS_SUCCESS_DF(df_providus_success):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"PROVIDUS SUCCESS\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "    sessionId_col = []\n",
        "    transaction_reference_col = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    list_column_none_providus_success = []\n",
        "    list_column_none_providus_success = [totalsent_col, \n",
        "                                        message_sms_payload_col, \n",
        "                                        cost_col, \n",
        "                                        status_col, \n",
        "                                        email_col, \n",
        "                                        phone_col, \n",
        "                                        endpoint_col, \n",
        "                                        date_col,\n",
        "                                        account_number_col, account_name_col, bvn_col,\n",
        "                                        requestSuccessful_col]\n",
        "\n",
        "\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col, \n",
        "                    sessionId_col, transaction_reference_col]\n",
        "\n",
        "    for index, row in df_providus_success.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        # check if the row contains \"info\" string\n",
        "        if re.search('info', str_text):\n",
        "            log_level = re.search('info', str_text)\n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)             \n",
        "            if 'mailto' not in str_text:\n",
        "                if re.search('PROVIDUS SUCCESS', str_text):\n",
        "                    providus_success = parse_wallet_sms_payload_success(str_text)\n",
        "                    type_of_request = re.search('PROVIDUS SUCCESS', str_text)\n",
        "                       \n",
        "                    try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                    except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                    try:\n",
        "                        responseCode_col.append(providus_success.get('responseCode'))\n",
        "                    except AttributeError:\n",
        "                        responseCode_col.append(None)\n",
        "                    try:\n",
        "                        responseMessage_col.append(providus_success.get('responseMessage'))\n",
        "                    except AttributeError:\n",
        "                        responseMessage_col.append(None)\n",
        "                    try:\n",
        "                        sessionId_col.append(providus_success.get('sessionId'))\n",
        "                    except AttributeError:\n",
        "                        sessionId_col.append(None)\n",
        "                    try:\n",
        "                        transaction_reference_col.append(providus_success.get('transactionReference'))\n",
        "                    except AttributeError:\n",
        "                        transaction_reference_col.append(None)\n",
        "\n",
        "                    for n in range(len(list_column_none_providus_success)):\n",
        "                        list_column_none_providus_success[n].append(None) \n",
        "              \n",
        "            elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "                type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "\n",
        "            elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "                type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "\n",
        "            elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "                type_of_request = re.search('VTPASS SUCCESS', str_text)\n",
        "\n",
        "    \n",
        "    df_providus_success['SessionId'] = sessionId_col\n",
        "    df_providus_success['Transaction_Reference'] = transaction_reference_col\n",
        "    df_providus_success['Type_Request'] = type_request_col\n",
        "    df_providus_success['Phone_Number'] = phone_col\n",
        "    df_providus_success['Date'] = date_col\n",
        "    df_providus_success['EndPoint'] = endpoint_col\n",
        "    df_providus_success['Log_Level'] = log_level_col\n",
        "    df_providus_success['Email'] = email_col\n",
        "    df_providus_success['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_providus_success['Total Sent'] = totalsent_col\n",
        "    df_providus_success['Cost'] = cost_col\n",
        "    df_providus_success['Status'] = status_col\n",
        "    df_providus_success['Account Number'] = account_number_col\n",
        "    df_providus_success['Account Name'] = account_name_col\n",
        "    df_providus_success['BVN'] = bvn_col\n",
        "    df_providus_success['Request Successful'] = requestSuccessful_col\n",
        "    df_providus_success['Response Message'] = responseMessage_col\n",
        "    df_providus_success['Response Code'] = responseCode_col\n",
        " \n",
        "    return df_providus_success\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWCAd27TdGCe"
      },
      "source": [
        "providus_success_df = df_raw[df_raw['text'].str.contains('PROVIDUS SUCCESS')]\n",
        "df_providus_success = parse_PROVIDUS_SUCCESS_DF(providus_success_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqmXhbXFiW29"
      },
      "source": [
        "df_providus_success.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5AkmLaNdbcS"
      },
      "source": [
        "Handle DataFrame for VTPASS PAYLOAD Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj5XJfcXdb40"
      },
      "source": [
        "def parse_VTPASS_PAYLOAD_DF(df_vtpass_payload):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"VTPASS PAYLOAD\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    {'amount': 50,\n",
        " 'phone': '08165967191 ',\n",
        " 'request_id': '08165967191-1616853478772 ',\n",
        " 'serviceID': 'mtn '}\n",
        "\n",
        "    amount_col = []\n",
        "    request_id_col = []\n",
        "    serviceID_col = []\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "\n",
        "\n",
        "    list_column_none_providus_success = []\n",
        "    list_column_none_providus_success = [totalsent_col, \n",
        "                                        message_sms_payload_col, \n",
        "                                        cost_col, \n",
        "                                        status_col, \n",
        "                                        email_col, \n",
        "                                        endpoint_col, \n",
        "                                        date_col,\n",
        "                                        account_number_col, account_name_col, bvn_col,\n",
        "                                        requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col,\n",
        "                    amount_col, request_id_col, serviceID_col]\n",
        "\n",
        "    for index, row in df_vtpass_payload.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        # check if the row contains \"info\" string\n",
        "        if re.search('info', str_text):\n",
        "            log_level = re.search('info', str_text)\n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)             \n",
        "            if 'mailto' not in str_text:\n",
        "                if re.search('VTPASS PAYLOAD', str_text):\n",
        "                    providus_success = parse_wallet_sms_payload_success(str_text)\n",
        "                    type_of_request = re.search('VTPASS PAYLOAD', str_text)\n",
        "                       \n",
        "                    try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                    except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                    try:\n",
        "                        amount_col.append(providus_success.get('amount'))\n",
        "                    except AttributeError:\n",
        "                        amount_col.append(None)\n",
        "                    try:\n",
        "                        phone_col.append(providus_success.get('phone'))\n",
        "                    except AttributeError:\n",
        "                        phone_col.append(None)\n",
        "                    try:\n",
        "                        request_id_col.append(providus_success.get('request_id'))\n",
        "                    except AttributeError:\n",
        "                        request_id_col.append(None)\n",
        "                    try:\n",
        "                        serviceID_col.append(providus_success.get('serviceID'))\n",
        "                    except AttributeError:\n",
        "                        serviceID_col.append(None)\n",
        "\n",
        "                    for n in range(len(list_column_none_providus_success)):\n",
        "                        list_column_none_providus_success[n].append(None) \n",
        "              \n",
        "\n",
        "\n",
        "    df_vtpass_payload['Service_ID'] = serviceID_col\n",
        "    df_vtpass_payload['Amount'] = amount_col\n",
        "    df_vtpass_payload['Request_Id'] = request_id_col\n",
        "    df_vtpass_payload['Type_Request'] = type_request_col\n",
        "    df_vtpass_payload['Phone_Number'] = phone_col\n",
        "    df_vtpass_payload['Date'] = date_col\n",
        "    df_vtpass_payload['EndPoint'] = endpoint_col\n",
        "    df_vtpass_payload['Log_Level'] = log_level_col\n",
        "    df_vtpass_payload['Email'] = email_col\n",
        "    df_vtpass_payload['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_vtpass_payload['Total Sent'] = totalsent_col\n",
        "    df_vtpass_payload['Cost'] = cost_col\n",
        "    df_vtpass_payload['Status'] = status_col\n",
        "    df_vtpass_payload['Account Number'] = account_number_col\n",
        "    df_vtpass_payload['Account Name'] = account_name_col\n",
        "    df_vtpass_payload['BVN'] = bvn_col\n",
        "    df_vtpass_payload['Request Successful'] = requestSuccessful_col\n",
        "    df_vtpass_payload['Response Message'] = responseMessage_col\n",
        "    df_vtpass_payload['Response Code'] = responseCode_col\n",
        " \n",
        "    return df_vtpass_payload\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPHvlp86deaH"
      },
      "source": [
        "vtpass_payload = df_raw[df_raw['text'].str.contains('VTPASS PAYLOAD')]\n",
        "df_vtpass_payload = parse_VTPASS_PAYLOAD_DF(vtpass_payload)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJPBtSi_im1d"
      },
      "source": [
        "df_vtpass_payload.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV2OBj_kxLGp"
      },
      "source": [
        "Handle DataFrame for LEADWAY ERROR Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWThX6Dhd-4G"
      },
      "source": [
        "def parse_LEADWAY_ERROR_DF(df_leadway_error):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"LEADWAY ERROR\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "    error_code_col = []\n",
        "    error_number_col = []\n",
        "    port_col = []\n",
        "    syscall_col = []\n",
        "    address_col = []\n",
        "  \n",
        "    #list_column_none_level_log_error = []\n",
        "    # columns set to None\n",
        "    list_column_none = [message_sms_payload_col, totalsent_col, cost_col, status_col, email_col,\n",
        "                        endpoint_col, date_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                        responseCode_col, account_name_col, account_number_col, phone_col]\n",
        "    \n",
        "\n",
        "    # columns which will be populated\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col,\n",
        "                    error_code_col, error_number_col, port_col, syscall_col, \n",
        "                    address_col]\n",
        "\n",
        "    for index, row in df_leadway_error.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        if re.search('error', str_text):\n",
        "            log_level = re.search('error', str_text)\n",
        "                \n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)\n",
        "\n",
        "            if re.search('LEADWAY ERROR', str_text):\n",
        "                type_of_request = re.search('LEADWAY ERROR', str_text)\n",
        "                leadway_error = parse_wallet_sms_payload_success(str_text)\n",
        "                try:\n",
        "                    error_code_col.append(leadway_error.get('code'))\n",
        "                except AttributeError:\n",
        "                    error_code_col.append(None)\n",
        "                try:\n",
        "                    error_number_col.append(leadway_error.get('errno'))\n",
        "                except AttributeError:\n",
        "                    error_number_col.append(None)\n",
        "                try:\n",
        "                    address_col.append(leadway_error.get('address'))\n",
        "                except AttributeError:\n",
        "                    address_col.append(None)\n",
        "                try:\n",
        "                    port_col.append(leadway_error.get('port'))\n",
        "                except AttributeError:\n",
        "                    port_col.append(None)\n",
        "                try:\n",
        "                    syscall_col.append(leadway_error.get('syscall'))\n",
        "                except AttributeError:\n",
        "                    syscall_col.append(None)      \n",
        "                try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "\n",
        "                for p in range(len(list_column_none)):\n",
        "                    list_column_none[p].append(None)\n",
        "\n",
        "    # set columns to their corresponding list values\n",
        "\n",
        "    df_leadway_error['Type_Request'] = type_request_col\n",
        "    df_leadway_error['Phone_Number'] =phone_col\n",
        "    df_leadway_error['Date'] = date_col\n",
        "    df_leadway_error['EndPoint'] = endpoint_col\n",
        "    df_leadway_error['Log_Level'] = log_level_col\n",
        "    df_leadway_error['Email'] = email_col\n",
        "    df_leadway_error['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_leadway_error['Total Sent'] = totalsent_col\n",
        "    df_leadway_error['Cost'] = cost_col\n",
        "    df_leadway_error['Status'] = status_col\n",
        "    df_leadway_error['Account Number'] = account_number_col\n",
        "    df_leadway_error['Account Name'] = account_name_col\n",
        "    df_leadway_error['BVN'] = bvn_col\n",
        "    df_leadway_error['Request Successful'] = requestSuccessful_col\n",
        "    df_leadway_error['Response Message'] = responseMessage_col\n",
        "    df_leadway_error['Response Code'] = responseCode_col\n",
        "    df_leadway_error['Error Code'] = error_code_col\n",
        "    df_leadway_error['Error Number'] = error_number_col\n",
        "    df_leadway_error['Error Port'] = port_col\n",
        "    df_leadway_error['Error Syscall'] = syscall_col\n",
        "    df_leadway_error['Error Address'] = address_col\n",
        "\n",
        "\n",
        "    return df_leadway_error\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viASPHzLeBOc"
      },
      "source": [
        "lead_error = df_raw[df_raw['text'].str.contains('LEADWAY ERROR')]\n",
        "df_lead_error = parse_LEADWAY_ERROR_DF(lead_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b136VEIsiyUv"
      },
      "source": [
        "df_lead_error.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg7u65AZxluN"
      },
      "source": [
        "Handle DataFrame for PROVIDUS TRANSFER ERROR Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsgEs6lNxYET"
      },
      "source": [
        "def parse_PROVIDUS_TRANSFER_ERROR_DF(df_providus_transfer_error):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"PROVIDUS TRANSFER ERROR\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "    error_code_col = []\n",
        "    error_number_col = []\n",
        "    port_col = []\n",
        "    syscall_col = []\n",
        "    address_col = []\n",
        "  \n",
        "    #list_column_none_level_log_error = []\n",
        "    # columns set to None\n",
        "    list_column_none = [message_sms_payload_col, totalsent_col, cost_col, status_col, email_col,\n",
        "                        endpoint_col, date_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                        responseCode_col, account_name_col, account_number_col, phone_col]\n",
        "    \n",
        "\n",
        "    # columns which will be populated\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col,\n",
        "                    error_code_col, error_number_col, port_col, syscall_col, \n",
        "                    address_col]  \n",
        "\n",
        "    for index, row in df_providus_transfer_error.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        if re.search('error', str_text):\n",
        "            log_level = re.search('error', str_text)\n",
        "                \n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)\n",
        "\n",
        "            if re.search('PROVIDUS TRANSFER ERROR', str_text):\n",
        "                type_of_request = re.search('PROVIDUS TRANSFER ERROR', str_text)\n",
        "                leadway_error = parse_providus_transfer_error_function(str_text)\n",
        "                try:\n",
        "                    error_code_col.append(leadway_error.get('code'))\n",
        "                except AttributeError:\n",
        "                    error_code_col.append(None)\n",
        "                try:\n",
        "                    error_number_col.append(leadway_error.get('errno'))\n",
        "                except AttributeError:\n",
        "                    error_number_col.append(None)\n",
        "                try:\n",
        "                    address_col.append(leadway_error.get('address'))\n",
        "                except AttributeError:\n",
        "                    address_col.append(None)\n",
        "                try:\n",
        "                    port_col.append(leadway_error.get('port'))\n",
        "                except AttributeError:\n",
        "                    port_col.append(None)\n",
        "                try:\n",
        "                    syscall_col.append(leadway_error.get('syscall'))\n",
        "                except AttributeError:\n",
        "                    syscall_col.append(None)      \n",
        "                try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "\n",
        "                for p in range(len(list_column_none)):\n",
        "                    list_column_none[p].append(None)\n",
        "\n",
        "    # set columns to their corresponding list values\n",
        "\n",
        "    df_providus_transfer_error['Type_Request'] = type_request_col\n",
        "    df_providus_transfer_error['Phone_Number'] =phone_col\n",
        "    df_providus_transfer_error['Date'] = date_col\n",
        "    df_providus_transfer_error['EndPoint'] = endpoint_col\n",
        "    df_providus_transfer_error['Log_Level'] = log_level_col\n",
        "    df_providus_transfer_error['Email'] = email_col\n",
        "    df_providus_transfer_error['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_providus_transfer_error['Total Sent'] = totalsent_col\n",
        "    df_providus_transfer_error['Cost'] = cost_col\n",
        "    df_providus_transfer_error['Status'] = status_col\n",
        "    df_providus_transfer_error['Account Number'] = account_number_col\n",
        "    df_providus_transfer_error['Account Name'] = account_name_col\n",
        "    df_providus_transfer_error['BVN'] = bvn_col\n",
        "    df_providus_transfer_error['Request Successful'] = requestSuccessful_col\n",
        "    df_providus_transfer_error['Response Message'] = responseMessage_col\n",
        "    df_providus_transfer_error['Response Code'] = responseCode_col\n",
        "    df_providus_transfer_error['Error Code'] = error_code_col\n",
        "    df_providus_transfer_error['Error Number'] = error_number_col\n",
        "    df_providus_transfer_error['Error Port'] = port_col\n",
        "    df_providus_transfer_error['Error Syscall'] = syscall_col\n",
        "    df_providus_transfer_error['Error Address'] = address_col\n",
        "\n",
        "\n",
        "    return df_providus_transfer_error\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLJ1mqMJxbCn"
      },
      "source": [
        "providus_transfer_error = df_raw[df_raw['text'].str.contains('PROVIDUS TRANSFER ERROR')]\n",
        "df_providus_transfer_error = parse_PROVIDUS_TRANSFER_ERROR_DF(providus_transfer_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXv7dx4wi7a0"
      },
      "source": [
        "df_providus_transfer_error.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjy32dtmyQJS"
      },
      "source": [
        "Handle DataFrame for PROVIDUS TRANSFER SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmn8hk_ZyGAz"
      },
      "source": [
        "\n",
        "def parse_PROVIDUS_TRANSFER_SUCCESS_DF(df_providus_transfer_success):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"PROVIDUS TRANSFER SUCCESS\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "    sessionId_col = []\n",
        "    transaction_reference_col = []\n",
        "    message_error_col = []\n",
        "\n",
        "\n",
        "    list_column_none_providus_success = []\n",
        "    list_column_none_providus_success = [totalsent_col, \n",
        "                                        message_sms_payload_col, \n",
        "                                        cost_col, \n",
        "                                        status_col, \n",
        "                                        email_col, \n",
        "                                        phone_col, \n",
        "                                        endpoint_col, \n",
        "                                        date_col,\n",
        "                                        account_number_col, account_name_col, bvn_col,\n",
        "                                        requestSuccessful_col]\n",
        "\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col, \n",
        "                    sessionId_col, transaction_reference_col]\n",
        "\n",
        "    for index, row in df_providus_transfer_success.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        # check if the row contains \"info\" string\n",
        "        if re.search('info', str_text):\n",
        "            log_level = re.search('info', str_text)\n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None) \n",
        "\n",
        "            if re.search('PROVIDUS TRANSFER SUCCESS', str_text):\n",
        "              \n",
        "              if 'Faithfully yours, nginx' in str_text:\n",
        "                  error_text = 'Sorry, the page you are looking for is currently unavailable, Please try again later.'\n",
        "                  message_error_col.append(error_text)\n",
        "                  responseCode_col.append(None)\n",
        "                  responseMessage_col.append(None)\n",
        "                  sessionId_col.append(None)\n",
        "                  transaction_reference_col.append(None)\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "              else:\n",
        "                  message_error_col.append(None)\n",
        "                  try:\n",
        "                    providus_transfer_success = parse_wallet_sms_payload_success(str_text)\n",
        "                  except json.decoder.JSONDecodeError:\n",
        "                    print(str_text)\n",
        "                    raise\n",
        "\n",
        "                  type_of_request = re.search('PROVIDUS TRANSFER SUCCESS', str_text)\n",
        "                      \n",
        "                  try:\n",
        "                      type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                      type_request_col.append(None)\n",
        "                  try:\n",
        "                      responseCode_col.append(providus_transfer_success.get('responseCode'))\n",
        "                  except AttributeError:\n",
        "                      responseCode_col.append(None)\n",
        "                  try:\n",
        "                      responseMessage_col.append(providus_transfer_success.get('responseMessage'))\n",
        "                  except AttributeError:\n",
        "                      responseMessage_col.append(None)\n",
        "                  try:\n",
        "                      sessionId_col.append(providus_transfer_success.get('sessionId'))\n",
        "                  except AttributeError:\n",
        "                      sessionId_col.append(None)\n",
        "                  try:\n",
        "                      transaction_reference_col.append(providus_transfer_success.get('transactionReference'))\n",
        "                  except AttributeError:\n",
        "                      transaction_reference_col.append(None)\n",
        "              for n in range(len(list_column_none_providus_success)):\n",
        "                  list_column_none_providus_success[n].append(None) \n",
        "    \n",
        "    df_providus_transfer_success['SessionId'] = sessionId_col\n",
        "    df_providus_transfer_success['Transaction_Reference'] = transaction_reference_col\n",
        "    df_providus_transfer_success['Type_Request'] = type_request_col\n",
        "    df_providus_transfer_success['Phone_Number'] = phone_col\n",
        "    df_providus_transfer_success['Date'] = date_col\n",
        "    df_providus_transfer_success['EndPoint'] = endpoint_col\n",
        "    df_providus_transfer_success['Log_Level'] = log_level_col\n",
        "    df_providus_transfer_success['Email'] = email_col\n",
        "    df_providus_transfer_success['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_providus_transfer_success['Total Sent'] = totalsent_col\n",
        "    df_providus_transfer_success['Cost'] = cost_col\n",
        "    df_providus_transfer_success['Status'] = status_col\n",
        "    df_providus_transfer_success['Account Number'] = account_number_col\n",
        "    df_providus_transfer_success['Account Name'] = account_name_col\n",
        "    df_providus_transfer_success['BVN'] = bvn_col\n",
        "    df_providus_transfer_success['Request Successful'] = requestSuccessful_col\n",
        "    df_providus_transfer_success['Response Message'] = responseMessage_col\n",
        "    df_providus_transfer_success['Response Code'] = responseCode_col\n",
        "    df_providus_transfer_success['Error Message Providus Transfer'] = message_error_col\n",
        " \n",
        "    return df_providus_transfer_success\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZPumx0gyI9w"
      },
      "source": [
        "providus_transfer_success = df_raw[df_raw['text'].str.contains('PROVIDUS TRANSFER SUCCESS')]\n",
        "df_providus_transfer_success = parse_PROVIDUS_TRANSFER_SUCCESS_DF(providus_transfer_success)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqVwdhijKr0"
      },
      "source": [
        "df_providus_transfer_success.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYqmcPFSyvo4"
      },
      "source": [
        "def parse_PROVIDUS_SETTLEMENT_INFO_DF(df_providus_settlement_info):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"PROVIDUS SETTLEMENT INFO\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    log_level_col = []\n",
        "    api_request_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "    sessionId_col = []\n",
        "    channelId_col = []\n",
        "    feeAmount_col = []\n",
        "    currency_col = []\n",
        "    initiation_tranRef_col = []\n",
        "    settled_amount_col = []\n",
        "    settlementId_col = []\n",
        "    source_account_name_col = []\n",
        "    source_account_number_col = []\n",
        "    source_bank_name_col = []\n",
        "    tran_date_time_col = []\n",
        "    tran_remarks_col = []\n",
        "    transaction_amount_col = []\n",
        "    vat_amount_col = []\n",
        "\n",
        "\n",
        "    list_column_none_providus_success = []\n",
        "    list_column_none_providus_success = [totalsent_col, \n",
        "                                        message_sms_payload_col, \n",
        "                                        cost_col, \n",
        "                                        status_col, \n",
        "                                        email_col, \n",
        "                                        phone_col, \n",
        "                                        endpoint_col, \n",
        "                                        date_col,\n",
        "                                        account_name_col, bvn_col,\n",
        "                                        requestSuccessful_col, responseCode_col, responseMessage_col]\n",
        "\n",
        "\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col, \n",
        "                    sessionId_col, channelId_col, feeAmount_col, currency_col, initiation_tranRef_col,\n",
        "                    settled_amount_col, settlementId_col, source_account_name_col, source_account_number_col,\n",
        "                    source_bank_name_col, tran_date_time_col, tran_remarks_col, transaction_amount_col, vat_amount_col]\n",
        "\n",
        "    for index, row in df_providus_settlement_info.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        # check if the row contains \"info\" string\n",
        "        if re.search('info', str_text):\n",
        "            log_level = re.search('info', str_text)\n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)             \n",
        "            if 'mailto' not in str_text:\n",
        "                if re.search('PROVIDUS SETTLEMENT INFO', str_text):\n",
        "                    providus_settlement_info = parse_wallet_sms_payload_success(str_text)\n",
        "                    #print(providus_settlement_info)\n",
        "                    type_of_request = re.search('PROVIDUS SETTLEMENT INFO', str_text)\n",
        "          \n",
        "                    try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                    except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                    try:\n",
        "                        account_number_col.append(providus_settlement_info.get('accountNumber'))\n",
        "                    except AttributeError:\n",
        "                        account_number_col.append(None)\n",
        "                    try:\n",
        "                        channelId_col.append(providus_settlement_info.get('channelId'))\n",
        "                    except AttributeError:\n",
        "                        channelId_col.append(None)\n",
        "                    try:\n",
        "                        sessionId_col.append(providus_settlement_info.get('sessionId'))\n",
        "                    except AttributeError:\n",
        "                        sessionId_col.append(None)\n",
        "                    try:\n",
        "                        currency_col.append(providus_settlement_info.get('currency'))\n",
        "                    except AttributeError:\n",
        "                        currency_col.append(None)\n",
        "                    try:\n",
        "                        feeAmount_col.append(providus_settlement_info.get('feeAmount'))\n",
        "                    except AttributeError:\n",
        "                        feeAmount_col.append(None)\n",
        "                    try:\n",
        "                        initiation_tranRef_col.append(providus_settlement_info.get('initiationTranRef'))\n",
        "                    except AttributeError:\n",
        "                        initiation_tranRef_col.append(None)\n",
        "                    try:\n",
        "                        settled_amount_col.append(providus_settlement_info.get('settledAmount'))\n",
        "                    except AttributeError:\n",
        "                        settled_amount_col.append(None)\n",
        "                    try:\n",
        "                        settlementId_col.append(providus_settlement_info.get('settlementId'))\n",
        "                    except AttributeError:\n",
        "                        settlementId_col.append(None)\n",
        "                    try:\n",
        "                        source_account_name_col.append(providus_settlement_info.get('sourceAccountName'))\n",
        "                    except AttributeError:\n",
        "                        source_account_name_col.append(None)\n",
        "                    try:\n",
        "                        source_account_number_col.append(providus_settlement_info.get('sourceAccountNumber'))\n",
        "                    except AttributeError:\n",
        "                        source_account_number_col.append(None)\n",
        "                    try:\n",
        "                        source_bank_name_col.append(providus_settlement_info.get('sourceBankName'))\n",
        "                    except AttributeError:\n",
        "                        source_bank_name_col.append(None)\n",
        "                    try:\n",
        "                        tran_date_time_col.append(providus_settlement_info.get('tranDateTime'))\n",
        "                    except AttributeError:\n",
        "                        tran_date_time_col.append(None)\n",
        "                    try:\n",
        "                        tran_remarks_col.append(providus_settlement_info.get('tranRemarks'))\n",
        "                    except AttributeError:\n",
        "                        tran_remarks_col.append(None)\n",
        "                    try:\n",
        "                        transaction_amount_col.append(providus_settlement_info.get('transactionAmount'))\n",
        "                    except AttributeError:\n",
        "                        transaction_amount_col.append(None)\n",
        "                    try:\n",
        "                        vat_amount_col.append(providus_settlement_info.get('vatAmount'))\n",
        "                    except AttributeError:\n",
        "                        vat_amount_col.append(None)\n",
        "\n",
        "                    for n in range(len(list_column_none_providus_success)):\n",
        "                        list_column_none_providus_success[n].append(None) \n",
        "\n",
        "    \n",
        "    df_providus_settlement_info['Vat_Amount'] = vat_amount_col\n",
        "    df_providus_settlement_info['Transaction_Amount'] = transaction_amount_col\n",
        "    df_providus_settlement_info['Tran_Remarks'] = tran_remarks_col\n",
        "    df_providus_settlement_info['Tran_Date_Time'] = tran_date_time_col\n",
        "    df_providus_settlement_info['Source_Bank_Name'] = source_bank_name_col\n",
        "    df_providus_settlement_info['Source_Account_Number'] = source_account_number_col\n",
        "    df_providus_settlement_info['Source_Account_Name'] = source_account_name_col\n",
        "    df_providus_settlement_info['SettlementId'] = settlementId_col\n",
        "    df_providus_settlement_info['settled_Amount'] = settled_amount_col\n",
        "    df_providus_settlement_info['Initiation_TranRef'] = initiation_tranRef_col\n",
        "    df_providus_settlement_info['FeeAmount'] = feeAmount_col\n",
        "    df_providus_settlement_info['Currency'] = currency_col\n",
        "    df_providus_settlement_info['ChannelId'] = channelId_col\n",
        "    df_providus_settlement_info['SessionId'] = sessionId_col\n",
        "    df_providus_settlement_info['Type_Request'] = type_request_col\n",
        "    df_providus_settlement_info['Phone_Number'] = phone_col\n",
        "    df_providus_settlement_info['Date'] = date_col\n",
        "    df_providus_settlement_info['EndPoint'] = endpoint_col\n",
        "    df_providus_settlement_info['Log_Level'] = log_level_col\n",
        "    df_providus_settlement_info['Email'] = email_col\n",
        "    df_providus_settlement_info['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_providus_settlement_info['Total Sent'] = totalsent_col\n",
        "    df_providus_settlement_info['Cost'] = cost_col\n",
        "    df_providus_settlement_info['Status'] = status_col\n",
        "    df_providus_settlement_info['Account Number'] = account_number_col\n",
        "    df_providus_settlement_info['Account Name'] = account_name_col\n",
        "    df_providus_settlement_info['BVN'] = bvn_col\n",
        "    df_providus_settlement_info['Request Successful'] = requestSuccessful_col\n",
        "    df_providus_settlement_info['Response Message'] = responseMessage_col\n",
        "    df_providus_settlement_info['Response Code'] = responseCode_col\n",
        " \n",
        "    return df_providus_settlement_info\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioxUKvX0yzEj"
      },
      "source": [
        "providus_settlement_info = df_raw[df_raw['text'].str.contains('PROVIDUS SETTLEMENT INFO')]\n",
        "df_providus_settlement_info = parse_PROVIDUS_SETTLEMENT_INFO_DF(providus_settlement_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxmYw6dGjSYv"
      },
      "source": [
        "df_providus_settlement_info.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-g1LdhAzRIy"
      },
      "source": [
        "def parse_PROVIDUS_VERIFY_SETTLEMENT_INFO_DF(df_providus_verify_settlement_info):\n",
        "    \"\"\"\n",
        "    la fonction permet de parser les types de requete \"PROVIDUS VERIFY SETTLEMENT INFO\" sur tout le dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    log_level_col = []\n",
        "    type_request_col = []\n",
        "    phone_col = []\n",
        "    date_col = []\n",
        "    endpoint_col = []\n",
        "    email_col = []\n",
        "    message_sms_payload_col = []\n",
        "    totalsent_col = []\n",
        "    cost_col = []\n",
        "    status_col = []\n",
        "    account_number_col = []\n",
        "    account_name_col = []\n",
        "    bvn_col = []\n",
        "    requestSuccessful_col = []\n",
        "    responseMessage_col = []\n",
        "    responseCode_col = []\n",
        "    sessionId_col = []\n",
        "    channelId_col = []\n",
        "    feeAmount_col = []\n",
        "    currency_col = []\n",
        "    initiation_tranRef_col = []\n",
        "    settled_amount_col = []\n",
        "    settlementId_col = []\n",
        "    source_account_name_col = []\n",
        "    source_account_number_col = []\n",
        "    source_bank_name_col = []\n",
        "    tran_date_time_col = []\n",
        "    tran_remarks_col = []\n",
        "    transaction_amount_col = []\n",
        "    vat_amount_col = []\n",
        "\n",
        "\n",
        "    list_column_none_providus_success = []\n",
        "    list_column_none_providus_success = [totalsent_col, \n",
        "                                        message_sms_payload_col, \n",
        "                                        cost_col, \n",
        "                                        status_col, \n",
        "                                        email_col, \n",
        "                                        phone_col, \n",
        "                                        endpoint_col, \n",
        "                                        date_col,\n",
        "                                        account_name_col, bvn_col,\n",
        "                                        requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "\n",
        "    list_all_colum = []\n",
        "    list_all_colum = [type_request_col,phone_col, date_col, endpoint_col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col, \n",
        "                    sessionId_col, channelId_col, feeAmount_col, currency_col, initiation_tranRef_col,\n",
        "                    settled_amount_col, settlementId_col, source_account_name_col, source_account_number_col,\n",
        "                    source_bank_name_col, tran_date_time_col, tran_remarks_col, transaction_amount_col, vat_amount_col]\n",
        "\n",
        "    for index, row in df_providus_verify_settlement_info.iterrows():\n",
        "        str_text = row['text']\n",
        "\n",
        "        if not str_text.startswith('['):\n",
        "            for i in range(len(list_all_colum)):\n",
        "                list_all_colum[i].append(None)\n",
        "\n",
        "        # check if the row contains \"info\" string\n",
        "        if re.search('info', str_text):\n",
        "            log_level = re.search('info', str_text)\n",
        "            try:\n",
        "                log_level_col.append(log_level.group(0))\n",
        "            except AttributeError:\n",
        "                log_level_col.append(None)             \n",
        "            if 'mailto' not in str_text:\n",
        "                if re.search('PROVIDUS VERIFY SETTLEMENT INFO', str_text):\n",
        "                    providus_verify_settlement_info = parse_wallet_sms_payload_success(str_text)\n",
        "                    print(providus_verify_settlement_info)\n",
        "                    type_of_request = re.search('PROVIDUS VERIFY SETTLEMENT INFO', str_text)\n",
        "\n",
        "\n",
        "                    try:\n",
        "                        type_request_col.append(type_of_request.group(0))\n",
        "                    except AttributeError:\n",
        "                        type_request_col.append(None)\n",
        "                    try:\n",
        "                        account_number_col.append(providus_verify_settlement_info.get('accountNumber'))\n",
        "                    except AttributeError:\n",
        "                        account_number_col.append(None)\n",
        "                    try:\n",
        "                        channelId_col.append(providus_verify_settlement_info.get('channelId'))\n",
        "                    except AttributeError:\n",
        "                        channelId_col.append(None)\n",
        "                    try:\n",
        "                        sessionId_col.append(providus_verify_settlement_info.get('sessionId'))\n",
        "                    except AttributeError:\n",
        "                        sessionId_col.append(None)\n",
        "                    try:\n",
        "                        currency_col.append(providus_verify_settlement_info.get('currency'))\n",
        "                    except AttributeError:\n",
        "                        currency_col.append(None)\n",
        "                    try:\n",
        "                        feeAmount_col.append(providus_verify_settlement_info.get('feeAmount'))\n",
        "                    except AttributeError:\n",
        "                        feeAmount_col.append(None)\n",
        "                    try:\n",
        "                        initiation_tranRef_col.append(providus_verify_settlement_info.get('initiationTranRef'))\n",
        "                    except AttributeError:\n",
        "                        initiation_tranRef_col.append(None)\n",
        "                    try:\n",
        "                        settled_amount_col.append(providus_verify_settlement_info.get('settledAmount'))\n",
        "                    except AttributeError:\n",
        "                        settled_amount_col.append(None)\n",
        "                    try:\n",
        "                        settlementId_col.append(providus_verify_settlement_info.get('settlementId'))\n",
        "                    except AttributeError:\n",
        "                        settlementId_col.append(None)\n",
        "                    try:\n",
        "                        source_account_name_col.append(providus_verify_settlement_info.get('sourceAccountName'))\n",
        "                    except AttributeError:\n",
        "                        source_account_name_col.append(None)\n",
        "                    try:\n",
        "                        source_account_number_col.append(providus_verify_settlement_info.get('sourceAccountNumber'))\n",
        "                    except AttributeError:\n",
        "                        source_account_number_col.append(None)\n",
        "                    try:\n",
        "                        source_bank_name_col.append(providus_verify_settlement_info.get('sourceBankName'))\n",
        "                    except AttributeError:\n",
        "                        source_bank_name_col.append(None)\n",
        "                    try:\n",
        "                        tran_date_time_col.append(providus_verify_settlement_info.get('tranDateTime'))\n",
        "                    except AttributeError:\n",
        "                        tran_date_time_col.append(None)\n",
        "                    try:\n",
        "                        tran_remarks_col.append(providus_verify_settlement_info.get('tranRemarks'))\n",
        "                    except AttributeError:\n",
        "                        tran_remarks_col.append(None)\n",
        "                    try:\n",
        "                        transaction_amount_col.append(providus_verify_settlement_info.get('transactionAmount'))\n",
        "                    except AttributeError:\n",
        "                        transaction_amount_col.append(None)\n",
        "                    try:\n",
        "                        vat_amount_col.append(providus_verify_settlement_info.get('vatAmount'))\n",
        "                    except AttributeError:\n",
        "                        vat_amount_col.append(None)\n",
        "\n",
        "                    for n in range(len(list_column_none_providus_success)):\n",
        "                        list_column_none_providus_success[n].append(None)  \n",
        "    \n",
        "    df_providus_verify_settlement_info['Vat_Amount'] = vat_amount_col\n",
        "    df_providus_verify_settlement_info['Transaction_Amount'] = transaction_amount_col\n",
        "    df_providus_verify_settlement_info['Tran_Remarks'] = tran_remarks_col\n",
        "    df_providus_verify_settlement_info['Tran_Date_Time'] = tran_date_time_col\n",
        "    df_providus_verify_settlement_info['Source_Bank_Name'] = source_bank_name_col\n",
        "    df_providus_verify_settlement_info['Source_Account_Number'] = source_account_number_col\n",
        "    df_providus_verify_settlement_info['Source_Account_Name'] = source_account_name_col\n",
        "    df_providus_verify_settlement_info['SettlementId'] = settlementId_col\n",
        "    df_providus_verify_settlement_info['settled_Amount'] = settled_amount_col\n",
        "    df_providus_verify_settlement_info['Initiation_TranRef'] = initiation_tranRef_col\n",
        "    df_providus_verify_settlement_info['FeeAmount'] = feeAmount_col\n",
        "    df_providus_verify_settlement_info['Currency'] = currency_col\n",
        "    df_providus_verify_settlement_info['ChannelId'] = channelId_col\n",
        "    df_providus_verify_settlement_info['SessionId'] = sessionId_col\n",
        "    df_providus_verify_settlement_info['Type_Request'] = type_request_col\n",
        "    df_providus_verify_settlement_info['Phone_Number'] = phone_col\n",
        "    df_providus_verify_settlement_info['Date'] = date_col\n",
        "    df_providus_verify_settlement_info['EndPoint'] = endpoint_col\n",
        "    df_providus_verify_settlement_info['Log_Level'] = log_level_col\n",
        "    df_providus_verify_settlement_info['Email'] = email_col\n",
        "    df_providus_verify_settlement_info['Message SMS Payload'] = message_sms_payload_col\n",
        "    df_providus_verify_settlement_info['Total Sent'] = totalsent_col\n",
        "    df_providus_verify_settlement_info['Cost'] = cost_col\n",
        "    df_providus_verify_settlement_info['Status'] = status_col\n",
        "    df_providus_verify_settlement_info['Account Number'] = account_number_col\n",
        "    df_providus_verify_settlement_info['Account Name'] = account_name_col\n",
        "    df_providus_verify_settlement_info['BVN'] = bvn_col\n",
        "    df_providus_verify_settlement_info['Request Successful'] = requestSuccessful_col\n",
        "    df_providus_verify_settlement_info['Response Message'] = responseMessage_col\n",
        "    df_providus_verify_settlement_info['Response Code'] = responseCode_col\n",
        " \n",
        "    return df_providus_verify_settlement_info\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRUSLfr4zVJR"
      },
      "source": [
        "providus_verify_settlement_info = df_raw[df_raw['text'].str.contains('PROVIDUS VERIFY SETTLEMENT INFO')]\n",
        "df_providus_verify_settlement_info = parse_PROVIDUS_VERIFY_SETTLEMENT_INFO_DF(providus_verify_settlement_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcWUJ829jaOY"
      },
      "source": [
        "df_providus_verify_settlement_info.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRCfDmlrlBTd"
      },
      "source": [
        "pdList = [df_api_request, df_client_mobile_login, df_error, df_lead_error, df_okra_webhook, df_providus_payload, df_providus_settlement_info,\n",
        "          df_providus_success, df_providus_transfer_error, df_providus_transfer_success, df_providus_verify_settlement_info,\n",
        "          df_sms_payload, df_sms_success, df_vtpass_payload, df_wallet_success]  # List of our dataframes\n",
        "df_final = pd.concat(pdList)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfR-Jhhylc7j",
        "outputId": "81600de6-5de0-429a-c673-da5eba2328a5"
      },
      "source": [
        "df_final.info()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 90385 entries, 27302 to 91851\n",
            "Columns: 142 entries, type to Error Message Wallet\n",
            "dtypes: float64(7), object(135)\n",
            "memory usage: 98.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipUndaAClsTk"
      },
      "source": [
        "### Export DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-OennYvluQn"
      },
      "source": [
        "df_final.to_csv('/content/drive/MyDrive/datasets/final/nirra_log_bot_final.csv', index=None)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smVnWy7aOAxM",
        "outputId": "0222a7e7-2a8d-4384-ce84-779876a57101"
      },
      "source": [
        "len(df_final['Phone_Number'].unique())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5764"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSp3sqTVOSC9"
      },
      "source": [
        "df_final['Phone_Number'].unique() # récupérer la liste des différents numéros de téléphone\n",
        "all_users_phone_number = [element for element in df_final['Phone_Number'].unique() if element != None] # all userId\n",
        "#all_users_phone_number # liste de tous les différents numéros de téléphone."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCdVwWuhOype"
      },
      "source": [
        "all_df_phone_number = [] # to get list of dataframes\n",
        "for phoneNumber in tqdm(all_users_phone_number):\n",
        "  df_phone_number = df_final[df_final['Phone_Number'] == phoneNumber] # récupérer les dataframes avec seulement les numéros de téléphone\n",
        "  all_df_phone_number.append(df_phone_number)  # mettre chaque dataframe dans la\n",
        "\n",
        "all_df_phone_number[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PFhigDtPIgb"
      },
      "source": [
        "### sauvegarder les dataframes sur disque"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OJHQyIyQv66",
        "outputId": "c5586d4b-9575-4022-df11-c555789cb87d"
      },
      "source": [
        "from tqdm import tqdm\n",
        "# tqdm permet\n",
        "for phoneNumber in tqdm(all_users_phone_number):\n",
        "  df_phone_number = df_final[df_final['Phone_Number'] == phoneNumber]\n",
        "  df_phone_number.to_csv(f'/content/drive/MyDrive/datasets/final/files/{phoneNumber}.csv', index=None)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5763/5763 [01:41<00:00, 56.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn-ctLPXPN3B",
        "outputId": "3c221c7f-8ed7-4a9c-efab-a2f6693f6760"
      },
      "source": [
        "print(len(all_users_phone_number))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZh2y-x8PdIv",
        "outputId": "f7f09e71-1143-4af7-82b7-85c46acb4a54"
      },
      "source": [
        "cd /content/drive/MyDrive/datasets/final/files/"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets/final/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKBCBqvHPyZv"
      },
      "source": [
        "def isNaN(string):\n",
        "    return string != string"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jg94X1ZPzDf",
        "outputId": "c1df8e56-4e75-49c1-8397-69de0d93fbb1"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# use glob to get all the csv files \n",
        "# in the folder\n",
        "path = os.getcwd()\n",
        "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "all_df_list = [] # list of all dataframe\n",
        "# loop over the list of csv files\n",
        "number_transactions = []\n",
        "all_df_list_with_number_transaction = []\n",
        "list_df_with_diff_ts = []\n",
        "\n",
        "for f in tqdm(csv_files):    \n",
        "    # read the csv file\n",
        "    df = pd.read_csv(f)  \n",
        "    all_df_list.append(df)   \n",
        "\n",
        "for element in all_df_list:\n",
        "  element['Number_Transactions'] = element.shape[0] # faire la somme des lignes et mettre dans la colonne Number_Transactions\n",
        "  all_df_list_with_number_transaction.append(element)# mettre tous les éléments dans une nouvelle liste\n",
        "\n",
        "#Faire la différence entre les timestamp\n",
        "for ele_with_num_trans in all_df_list_with_number_transaction:\n",
        "  df_ts = pd.DataFrame(ele_with_num_trans['ts'])\n",
        "  ele_with_num_trans['ts_diff'] = df_ts.diff(axis=0)\n",
        "  list_df_with_diff_ts.append(ele_with_num_trans)\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5763/5763 [00:55<00:00, 104.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2pcP8awSqNi"
      },
      "source": [
        "### Entrainer premièrement le modèle global"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UElUbtcVSxG3",
        "outputId": "dadf85b1-41cb-4724-ff4c-b453ea4c883a"
      },
      "source": [
        "# avoir la distribution des nombres de transactions de tous les utilisateurs et faire un histogramme\n",
        "list_number_transactions = []\n",
        "for ele in tqdm(list_df_with_diff_ts):\n",
        "  if len(ele) > 0:\n",
        "    list_number_transactions.append(ele['Number_Transactions'][0])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5763/5763 [00:01<00:00, 5143.73it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NWWTqVcZ8OU",
        "outputId": "e80e9918-635a-4729-f3f2-f1d14a75d57b"
      },
      "source": [
        "max(list_number_transactions)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "939"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGmvbJ6Mh5iL"
      },
      "source": [
        "### Tracer l'histogramme logarithme en fonction de la liste contenant le nombre de transactions pour chaque utilisateur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-ZVXZUXI4W"
      },
      "source": [
        "df_liste_transactions = pd.DataFrame(list_number_transactions, columns=['Number_Transactions_per_user'])"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KvGEP4sHX-XP",
        "outputId": "7b48b235-a79d-4834-f329-7324d79108cf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# tracer un histogramme logarithmique\n",
        "y = pd.Series(list_number_transactions)\n",
        "hist, bins, _ = plt.hist(y, bins=8)\n",
        "logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
        "plt.yscale('log', nonposy='clip')\n",
        "plt.hist(y, bins=logbins)\n",
        "plt.show()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrbjuOgVggif"
      },
      "source": [
        "### récupérer la liste des utilisateurs qui pourraient etre problématiques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwmkUFm-ggIK",
        "outputId": "1f2c52bc-824a-4614-8bf4-cf3d16ff0509"
      },
      "source": [
        "### selon l'histogramme on a environs une vingtaine d'utilisateurs qui ont effectué entre 400 et plus de 800 transactions\n",
        "# on peut essayer de récupérer la liste de ces utilisateurs et étudier leurs comportements\n",
        "# sauvegarder sur le disque la liste des utilisateurs ayant plus de 400 transactions\n",
        "liste_utilisateurs_problematiques = []\n",
        "for one_df_diff_ts in tqdm(list_df_with_diff_ts):\n",
        "  if one_df_diff_ts.shape[0] >= 400:\n",
        "    liste_utilisateurs_problematiques.append(one_df_diff_ts)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5763/5763 [00:00<00:00, 224571.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moMLUwSmivPA"
      },
      "source": [
        "len(liste_utilisateurs_problematiques)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTo0M5oBtT92"
      },
      "source": [
        "liste_utilisateurs_problematiques[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJACZBwwweyI"
      },
      "source": [
        "def check_row_notnull(df):\n",
        "  mask = df.notnull()\n",
        "    \n",
        "  # using dropna() method to drop NaN \n",
        "  # value rows\n",
        "  df = df.where(mask).dropna()\n",
        "  return df\n",
        "  "
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDG_gn8wjLMd"
      },
      "source": [
        "### sauvegarder ces utilisateurs dans le disque en local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAAWQ3KJjKT3",
        "outputId": "af711ebb-068f-4f85-cc01-4f583cc53f9f"
      },
      "source": [
        "for elem in tqdm(liste_utilisateurs_problematiques):\n",
        "  phone = elem['Phone_Number'][0]\n",
        "  elem.to_csv(f'/content/drive/MyDrive/datasets/final/users_problematics/{phone}.csv', index=None)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:01<00:00, 20.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8w2z-JgRnGz"
      },
      "source": [
        "### Création des times series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OEzZ5khRodR",
        "outputId": "529760ac-9f21-47b5-bdae-fd3930206ea1"
      },
      "source": [
        "all_df_res = []\n",
        "new_endpoint_col = []\n",
        "for new_data_frame in tqdm(liste_utilisateurs_problematiques):\n",
        "  new_data_frame['EndPoint'].fillna('', inplace=True) # modifie la colonne\n",
        "\n",
        "  new_data_frame['Appplication_get'] = new_data_frame['EndPoint'].str.contains('applications/get').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Payment'] = new_data_frame['EndPoint'].str.contains('payment').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Declined'] = new_data_frame['EndPoint'].str.contains('decline').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Preapprouved'] = new_data_frame['EndPoint'].str.contains('preapproved').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Accepted'] = new_data_frame['EndPoint'].str.contains('accept').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Lifestyle'] = new_data_frame['EndPoint'].str.contains('lifestyle').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Wallet_balance'] = new_data_frame['EndPoint'].str.contains('wallet/balance').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Adverts'] = new_data_frame['EndPoint'].str.contains('adverts').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Bank'] = new_data_frame['EndPoint'].str.contains('bank').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Updated'] = new_data_frame['EndPoint'].str.contains('update').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Products'] = new_data_frame['EndPoint'].str.contains('products').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Locations'] = new_data_frame['EndPoint'].str.contains('locations').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Client_Get'] = new_data_frame['EndPoint'].str.contains('client/get').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Client_V2_Create'] = new_data_frame['EndPoint'].str.contains('client/v2/create').astype(np.float).astype('Int32')\n",
        "  \n",
        "  \n",
        "  new_data_frame['Dummy'] = 0\n",
        "  new_data_frame['Payment_cumulative'] = new_data_frame.groupby(['Dummy'])['Payment'].cumsum()\n",
        "  new_data_frame['Decline_cumulative'] = new_data_frame.groupby(['Dummy'])['Declined'].cumsum()\n",
        "  new_data_frame['Application_get_cumulative'] = new_data_frame.groupby(['Dummy'])['Appplication_get'].cumsum()\n",
        "  new_data_frame['Preapprouved_cumulative'] = new_data_frame.groupby(['Dummy'])['Preapprouved'].cumsum()\n",
        "  new_data_frame['Accepted_cumulative'] = new_data_frame.groupby(['Dummy'])['Accepted'].cumsum()\n",
        "  new_data_frame['Lifestyle_cumulative'] = new_data_frame.groupby(['Dummy'])['Lifestyle'].cumsum()\n",
        "  new_data_frame['Wallet_balance_cumulative'] = new_data_frame.groupby(['Dummy'])['Wallet_balance'].cumsum()\n",
        "  new_data_frame['Adverts_cumulative'] = new_data_frame.groupby(['Dummy'])['Adverts'].cumsum()\n",
        "  new_data_frame['Bank_cumulative'] = new_data_frame.groupby(['Dummy'])['Bank'].cumsum()\n",
        "  new_data_frame['Update_cumulative'] = new_data_frame.groupby(['Dummy'])['Updated'].cumsum()\n",
        "  new_data_frame['Products_cumulative'] = new_data_frame.groupby(['Dummy'])['Products'].cumsum()\n",
        "  new_data_frame['Locations_cumulative'] = new_data_frame.groupby(['Dummy'])['Locations'].cumsum()\n",
        "  new_data_frame['Client_Get_cumulative'] = new_data_frame.groupby(['Dummy'])['Client_Get'].cumsum()\n",
        "  new_data_frame['Client_Get_cumulative'] = new_data_frame.groupby(['Dummy'])['Client_V2_Create'].cumsum()\n",
        "  all_df_res.append(new_data_frame)\n",
        "        "
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:00<00:00, 22.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxJeRHJ4z7CO"
      },
      "source": [
        "all_df_res[1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}